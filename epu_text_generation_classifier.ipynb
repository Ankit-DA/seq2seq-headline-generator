{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "epu_text_generation_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "KOrjJktpu0cC",
        "AXZle-5LZkjB",
        "3S-5BKEChgpq",
        "hioZ7gXmaJMy",
        "9UiXaHuOYivz",
        "wJCY2BMD2CdX",
        "XbhbEq9-9A7Z",
        "w8vUqu9N7NpW",
        "EefZgYg88oPh",
        "81HTYDq67tTo",
        "KQ8VXQ2p6LQT",
        "zmkJ4VqaIe3O",
        "iGGv0EvDTcTW",
        "oVeWZf9p8UGn",
        "kj5LxKYnCFX3",
        "1xag3OJ99izY",
        "3zRe_KTnpPWD",
        "gKBa1wAHjSJ8",
        "duFWMa2rpS70",
        "8_DvHO0gk6k2",
        "6cKQklyh69IR",
        "jwXOvKbwd6S6",
        "UA8c4ThZ92Sf",
        "gWYKomeIexMi",
        "Pl6fXnWKxc2I",
        "7TgMIknvGHx0",
        "W16x4sTQOoNq",
        "Z7F90iBW2hOB",
        "vXchsCil2hOD",
        "9ztp-30R2hOM",
        "xBUtRHhW2hOP",
        "3Otuo61YE_Y8",
        "amjVSGztK5WY",
        "gl8oFqagJo9Q",
        "KCxKGueHLCHc",
        "nPfwRuHyfsTg",
        "1nuzFDLhTNSi",
        "V6Wl80gD5rOK"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOrjJktpu0cC",
        "colab_type": "text"
      },
      "source": [
        "<a id='importpackages'></a>\n",
        "***\n",
        "# Import Packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XfUNhmyvKvz",
        "colab_type": "text"
      },
      "source": [
        "### Standard Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_VPPi8lvMgi",
        "colab_type": "code",
        "outputId": "e75879d8-f752-4303-e996-ac5e6f8ec571",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "import re\n",
        "\n",
        "!pip install pprint\n",
        "from pprint import pprint\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "\n",
        "pd.set_option(\"display.max_columns\", 50)\n",
        "pd.set_option('display.max_colwidth', 200)\n",
        "pd.options.display.max_rows = 1000\n",
        "pd.options.mode.chained_assignment = None\n",
        "df = pd.DataFrame\n",
        "\n",
        "plt.style.use('default')\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pprint in /usr/local/lib/python3.6/dist-packages (0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_t40kNU4vKnK",
        "colab_type": "text"
      },
      "source": [
        "### NLTK / NLP Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MXFVwthudLe",
        "colab_type": "code",
        "outputId": "c06a70bb-9b30-4031-9734-b5b8946a0575",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from string import ascii_letters, punctuation\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn import metrics\n",
        "\n",
        "!pip install nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "!pip install rouge\n",
        "from rouge import Rouge\n",
        "\n",
        "!pip install unidecode\n",
        "import unidecode\n",
        "\n",
        "!pip install spacy\n",
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "!pip install beautifulsoup4\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n",
            "Collecting rouge\n",
            "  Downloading https://files.pythonhosted.org/packages/63/ac/b93411318529980ab7f41e59ed64ec3ffed08ead32389e29eb78585dd55d/rouge-0.3.2-py3-none-any.whl\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-0.3.2\n",
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 4.2MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.1.1\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.1.9)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.21.0)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.0.8)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.17.5)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.2.4)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.1)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.9.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.6.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.11.28)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.1.0,>=7.0.8->spacy) (4.28.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (4.6.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbQ3vm48vbB0",
        "colab_type": "text"
      },
      "source": [
        "### Neural Net Modules (Keras | Tensorflow | GPT-2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4rseGcevbae",
        "colab_type": "code",
        "outputId": "329284ff-5a07-489f-c287-95029e9fe65d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "\n",
        "# !pip install tensorflow-gpu==2.0.0\n",
        "import tensorflow as tf\n",
        "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
        "\n",
        "import logging\n",
        "logging.getLogger('tensorflow').disabled = True\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.initializers import Constant\n",
        "\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, CuDNNLSTM, CuDNNGRU, LSTM, GRU, Embedding, Concatenate, TimeDistributed, Bidirectional, Dropout, GlobalAveragePooling1D\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.models import load_model, Model\n",
        "from tensorflow.python.keras.optimizers import Adam\n",
        "\n",
        "!pip install transformers\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/10/aeefced99c8a59d828a92cc11d213e2743212d3641c87c82d61b035a7d5c/transformers-2.3.0-py3-none-any.whl (447kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 4.8MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 40.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.10.47)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 39.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.47 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.13.47)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884629 sha256=437137a1c5414ed011b12c0b2f44270c03c7e97206d4fbc2e080e554e14c440c\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 transformers-2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXZle-5LZkjB",
        "colab_type": "text"
      },
      "source": [
        "# Read Data & Prep\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peO6zJx4ASjk",
        "colab_type": "text"
      },
      "source": [
        "### Mount to Google Drive & Change Directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xORd21oKrTEj",
        "colab_type": "code",
        "outputId": "55e3bb87-e1b7-4a66-d543-31116f56de93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cp02g4xqrXF4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/gdrive/My Drive/colab_notebooks/information_systems/data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szOya-qYQVOI",
        "colab_type": "text"
      },
      "source": [
        "### Import Custom Attention Module(s)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HR4QAMIQU7-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('custom_modules')\n",
        "\n",
        "from attention_01 import AttentionLayer\n",
        "from attention_02 import Attention"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3S-5BKEChgpq",
        "colab_type": "text"
      },
      "source": [
        "## Remove Duplicate Rows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54YCwG7DufvQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPU = pd.read_csv('EPU_fullset.csv', encoding=\"ISO-8859-1\")\n",
        "EPU = EPU.drop('Unnamed: 0', axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLJAZLOthgF5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPU.drop_duplicates(subset=None, keep='first', inplace=True)\n",
        "EPU.drop_duplicates(subset=['Article'], keep='first', inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hioZ7gXmaJMy",
        "colab_type": "text"
      },
      "source": [
        "# Headline Cleaning\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MggdvTD1AC9Q",
        "colab_type": "text"
      },
      "source": [
        "#### Build `papers` List & Remove Low-Count Papers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmEctNKRIzO9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count_papers = EPU['Newspaper'].value_counts()\n",
        "EPU = EPU[~EPU['Newspaper'].isin(count_papers[count_papers < 100].index)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRZE2Ck_VOjL",
        "colab_type": "code",
        "outputId": "32607616-71f5-4b42-a211-fec027a47e23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "papers = list(EPU['Newspaper'].value_counts().index)\n",
        "papers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The Washington Post',\n",
              " 'Pittsburgh Post-Gazette (Pennsylvania)',\n",
              " 'The Atlanta Journal-Constitution',\n",
              " 'St. Louis Post-Dispatch (Missouri)',\n",
              " 'USA Today',\n",
              " 'Star Tribune (Minneapolis, MN)',\n",
              " 'The Philadelphia Inquirer (Pennsylvania)',\n",
              " 'St. Petersburg Times (Florida)',\n",
              " 'The Orange County Register (California)',\n",
              " 'Tampa Bay Times',\n",
              " 'The New York Post']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-N4u3yJ2zzRB",
        "colab_type": "text"
      },
      "source": [
        "#### Remove Obituaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNK3VeIpmcsd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "interim = EPU.loc[EPU['Newspaper'] == 'Pittsburgh Post-Gazette (Pennsylvania)']\n",
        "months_regex = '(?:JANUARY|FEBRUARY|MARCH|APRIL|MAY|JUNE|JULY|AUGUST|SEPTEMBER|OCTOBER|NOVEMBER|DECEMBER)'\n",
        "interim['Obituary'] = interim['Headline'].apply(lambda header: 1 if re.match('.*\\;\\s' + months_regex + '\\s\\d+', header) else 0)\n",
        "interim = interim.loc[interim['Obituary'] == 1]\n",
        "obituary_indeces = interim.index\n",
        "EPU = EPU[~EPU.index.isin(obituary_indeces)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWSE5-LD1f_k",
        "colab_type": "text"
      },
      "source": [
        "### Trim Short Headlines\n",
        "***\n",
        "\n",
        "##### Remove headlines with less than 4 words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_XUY3VX1ivz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPU['Headline'] = EPU['Headline'].apply(lambda headline: '' if not len(str(headline).split()) >= 4 else headline)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vh28_uop9PRD",
        "colab_type": "text"
      },
      "source": [
        "### Define Headline Occurrence Counter Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_gDP5IC9Pnu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_headline_counter_dict():\n",
        "  \"\"\"Construct counter objects for commonly-occurring words / headlines.\"\"\"\n",
        "\n",
        "  papers = list(EPU[EPU.isin(count_papers.index[count_papers >= 100]).values]['Newspaper'].value_counts().index)\n",
        "  paper_data_dict = {}\n",
        "  for paper in papers:\n",
        "    temp = EPU.loc[EPU['Newspaper'] == paper]\n",
        "    temp_prefix_counter = Counter(temp['Headline'])\n",
        "    temp_prefix_words = re.sub('\\s\\s+' , ' ', temp['Headline'].str.cat(sep=' '))\n",
        "    temp_prefix_words_counter = Counter(temp_prefix_words.split())\n",
        "\n",
        "    paper_data_dict.update({paper: (temp_prefix_counter.most_common(100000), temp_prefix_words_counter.most_common(150))})\n",
        "\n",
        "  return paper_data_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4QAtNb5X8vR",
        "colab_type": "text"
      },
      "source": [
        "## All Caps Patterns\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cu3mEiOP807s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPU['Prefix'] = EPU['Headline'].apply(lambda header: re.findall('^[A-Z\\s\\W]{2,}[\\w\\W]\\s', str(header))[0].replace(';', '') if re.findall('^[A-Z\\s]{2,}[\\w\\W]\\s', str(header)) else '') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5552Z55BxHSq",
        "colab_type": "text"
      },
      "source": [
        "### Define Byline Cleaner\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbPEK-cmxHr4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def byline_cleaner(headline):\n",
        "  \"\"\"Small function for clearing 'byline' information in headlines.\"\"\"\n",
        "\n",
        "  if 'byline' in str(headline).lower():\n",
        "    cleaned = re.match('(.*)\\s*byline', str(headline), flags=re.IGNORECASE).group(1)\n",
        "    if len(cleaned.split()) >= 4:\n",
        "      headline = cleaned\n",
        "    else:\n",
        "      headline = ''\n",
        "\n",
        "  return headline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Slyotjh6vMDO",
        "colab_type": "text"
      },
      "source": [
        "### Seek Patterns to Remove"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kKZ1lacwaBvY",
        "colab": {}
      },
      "source": [
        "paper_data_dict = build_headline_counter_dict()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnCiBCgnWqkQ",
        "colab_type": "text"
      },
      "source": [
        "### Cleaner – Star Tribune"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Quh3PNxlcyNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def star_tribute_clean_caps(headline):\n",
        "  \"\"\"Cleaner function for Star Tribute headlines (capitalised patterns).\"\"\"\n",
        "\n",
        "  catch_phrases = [\n",
        "    'READERS WRITE',\n",
        "    'SUNDAY CONVERSATION',\n",
        "    'RASH REPORT',\n",
        "    'ON SMALL BUSINESS',\n",
        "    'ON BUSINESS',\n",
        "    'THE GOOD LIFE',\n",
        "    'HOT DISH',\n",
        "    'BRIEFS',\n",
        "    'STAR TRIBUNE',\n",
        "    'STAFF WRITERS',\n",
        "    'TRAVEL TROUBLESHOOTER',\n",
        "    'DATA DROP',\n",
        "    'NOTEBOOK',\n",
        "    'JUST LISTED',\n",
        "    'ART',\n",
        "    'ELECTION',\n",
        "    'POLITICAL'\n",
        "  ]\n",
        "\n",
        "  headline = byline_cleaner(headline)\n",
        "\n",
        "  contains = 1 if any(phrase in re.sub(punct_re_string, ' ', str(headline)) for phrase in catch_phrases) else 0\n",
        "  if contains:\n",
        "    contained_phrases = [phrase for phrase in catch_phrases if phrase in re.sub(punct_re_string, ' ', str(headline))]\n",
        "    cleaned = headline\n",
        "    for phrase in contained_phrases:\n",
        "      cleaned = re.sub(phrase, '', str(cleaned))\n",
        "\n",
        "    if len(cleaned.split()) >= 4:\n",
        "      headline = cleaned\n",
        "    else:\n",
        "      headline = ''\n",
        "\n",
        "  return headline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVbRTwZmWuGx",
        "colab_type": "text"
      },
      "source": [
        "### Cleaner – Tampa Bay Times"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKHxGnWnq7Nt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tampa_times_clean_caps(headline):\n",
        "  \"\"\"Cleaner function for Tampa Bay Times headlines.\"\"\"\n",
        "\n",
        "  catch_phrases = [\n",
        "    'BEYOND TAMPA',\n",
        "    'BUSINESS DIGEST',\n",
        "    'PERSONNEL APPOINTMENTS, PROMOTIONS AND ',\n",
        "    'HELP CHOOSE LETTER OF THE ',\n",
        "    'WE WANT YOUR NEWS',\n",
        "    ': DISTRICT'\n",
        "    \"AMY SCHERZER'S DIARY\",\n",
        "    'MOVERS & SHAKERS',\n",
        "    'BREAKING DOWN THE DEBATE',\n",
        "    'FOR A BETTER',\n",
        "    'HIGH FIVES'\n",
        "  ]\n",
        "\n",
        "  headline = byline_cleaner(headline)\n",
        "  \n",
        "  contains = 1 if any(phrase in str(headline) for phrase in catch_phrases) else 0\n",
        "  if contains:\n",
        "    contained_phrases = [phrase for phrase in catch_phrases if phrase in str(headline)]\n",
        "    cleaned = headline\n",
        "    for phrase in contained_phrases:\n",
        "      if phrase == ': DISTRICT':\n",
        "        cleaned = re.sub('.*\\: DISTRICT', '', str(cleaned))\n",
        "      else:\n",
        "        cleaned = re.sub(phrase, '', str(cleaned))\n",
        "\n",
        "    if len(cleaned.split()) >= 4:\n",
        "      headline = cleaned\n",
        "    else:\n",
        "      headline = ''\n",
        "  \n",
        "  return headline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlIEnAHLWx0P",
        "colab_type": "text"
      },
      "source": [
        "### Cleaner – Atlanta Journal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjIasLJzWyMe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def atlanta_journal_clean_caps(headline):\n",
        "  \"\"\"Cleaner function for Atlanta Journal headlines.\"\"\"\n",
        "  \n",
        "  headline = byline_cleaner(headline)\n",
        "    \n",
        "  if re.match('^.*\\;', str(headline)):\n",
        "    cleaned = re.sub('^.*\\;', '', str(headline))\n",
        "    if len(cleaned.split()) >= 4:\n",
        "      headline = cleaned\n",
        "    else:\n",
        "      headline = ''\n",
        "\n",
        "  return headline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pq3ZkQviW1Sr",
        "colab_type": "text"
      },
      "source": [
        "### Cleaner – Philadelphia Inquirer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-mt3njZPDFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def philly_inquirer_clean_caps(headline):\n",
        "  \"\"\"Cleaner function for Philadelphia Inquirer headlines.\"\"\"\n",
        "\n",
        "  catch_phrases = [\n",
        "    'LETTERS –',\n",
        "    'LETTERS:',\n",
        "    'AROUND THE WORLD',\n",
        "    'AREA VOTES IN CONGRESS',\n",
        "    'IN THE NATION',\n",
        "    'BRIEFCASE'\n",
        "  ]\n",
        "\n",
        "  headline = byline_cleaner(headline)\n",
        "  \n",
        "  contains = 1 if any(phrase in str(headline) for phrase in catch_phrases) else 0\n",
        "  if contains:\n",
        "    contained_phrases = [phrase for phrase in catch_phrases if phrase in str(headline)]\n",
        "    cleaned = headline\n",
        "    for phrase in contained_phrases:\n",
        "      if phrase == 'LETTERS –':\n",
        "        cleaned = re.sub('LETTERS\\s\\-\\–\\s.*\\d+', '', str(cleaned))\n",
        "      else:\n",
        "        cleaned = re.sub(phrase, '', str(cleaned))\n",
        "\n",
        "    if len(cleaned.split()) >= 4:\n",
        "      headline = cleaned\n",
        "    else:\n",
        "      headline = ''\n",
        "\n",
        "    if 'Get the latest business news, stock quotes, investor tools and sign up for Inquirer Business Update,' in headline:\n",
        "      headline = ''\n",
        "\n",
        "  return headline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQ06KsFFW9nH",
        "colab_type": "text"
      },
      "source": [
        "### Cleaner – USA Today"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFF_4dTlSwHB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def usa_today_clean_caps(headline):\n",
        "  \"\"\"Cleaner function for Philadelphia Inquirer headlines.\"\"\"\n",
        "\n",
        "  catch_phrases = [\n",
        "    'FIRST WORDS',\n",
        "    'FIRST WORD',\n",
        "    'USA TODAY',\n",
        "    'NUMBER OF THE DAY',\n",
        "    'STORY STOCKS',\n",
        "    'EXPERIENCE'\n",
        "  ]\n",
        "\n",
        "  headline = byline_cleaner(headline)\n",
        "  \n",
        "  contains = 1 if any(phrase in str(headline) for phrase in catch_phrases) else 0\n",
        "  if contains:\n",
        "    contained_phrases = [phrase for phrase in catch_phrases if phrase in str(headline)]\n",
        "    cleaned = headline\n",
        "    for phrase in contained_phrases:\n",
        "      if phrase == 'USA TODAY' and re.match('^USA TODAY.*', headline):\n",
        "        cleaned = re.sub(phrase, '', str(cleaned))\n",
        "      else:\n",
        "        cleaned = re.sub(phrase, '', str(cleaned))\n",
        "\n",
        "    if len(cleaned.split()) >= 4:\n",
        "      headline = cleaned\n",
        "    else:\n",
        "      headline = ''\n",
        "\n",
        "  if 'Corrections & Clarifications;' in str(headline):\n",
        "      headline = ''\n",
        "\n",
        "  if 'byline' in str(headline).lower():\n",
        "    cleaned = re.match('(.*)\\s*byline', str(headline), flags=re.IGNORECASE).group(1)\n",
        "    if len(cleaned.split()) >= 4:\n",
        "      headline = cleaned\n",
        "    else:\n",
        "      headline = ''\n",
        "\n",
        "  return headline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTt-uSW_eo9p",
        "colab_type": "text"
      },
      "source": [
        "### Map Cleaners"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0B9M4TAffQXy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "paper_method_map_caps = {\n",
        "    'The Washington Post': None,\n",
        "    'Tampa Bay Times': tampa_times_clean_caps,\n",
        "    'The Atlanta Journal-Constitution': atlanta_journal_clean_caps,\n",
        "    'Star Tribune (Minneapolis, MN)': star_tribute_clean_caps,\n",
        "    'USA TODAY': usa_today_clean_caps,\n",
        "    'The Philadelphia Inquirer': philly_inquirer_clean_caps,\n",
        "    'Orange County Register (California)': None,\n",
        "    'St. Louis Post-Dispatch (Missouri)': None,\n",
        "    'Pittsburgh Post-Gazette': None,\n",
        "    'St. Petersburg Times (Florida)': None\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kF5Q1xm92pMi",
        "colab_type": "text"
      },
      "source": [
        "### Run Cleaners"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-MzEiJ4edE_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "punct_re_string = '|'.join('\\\\' + char for char in punctuation)\n",
        "punct_re_string = r'['+punct_re_string+']'\n",
        "  \n",
        "for paper in papers:\n",
        "  if paper_method_map_caps.get(paper):\n",
        "    EPU.update(EPU.loc[EPU['Newspaper'] == paper, 'Headline'].apply(paper_method_map_caps.get(paper)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tcgISQSvvBpN"
      },
      "source": [
        "## Lowercase Patterns\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8z_hvfvw-cx",
        "colab_type": "text"
      },
      "source": [
        "### Near-Duplicate Cleaner Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6UgJ2jv-v63c",
        "colab": {}
      },
      "source": [
        "def duplicates_clean_lower(paper):\n",
        "  \"\"\"Cleaner function for duplicate articles.\"\"\"\n",
        "\n",
        "  paper_data_dict = build_headline_counter_dict()\n",
        "  paper_df = EPU.loc[EPU['Newspaper'] == paper]\n",
        "\n",
        "  catch_phrases_check = {headline_counter[0]: headline_counter[1] for headline_counter in paper_data_dict[paper][0] if headline_counter[1] > 1}\n",
        "  catch_phrases_remove = []\n",
        "\n",
        "  search_length = len(catch_phrases_check)\n",
        "  for i, (phrase, count) in enumerate(catch_phrases_check.items()):\n",
        "    matches = []\n",
        "\n",
        "    if count > 4:\n",
        "      catch_phrases_remove.append(phrase)\n",
        "\n",
        "    elif not phrase == '' and phrase:\n",
        "      temp_df = paper_df.loc[paper_df['Headline'] == phrase]\n",
        "      tf_idf = TfidfVectorizer().fit_transform(temp_df['Article'])\n",
        "      pairwise_similarity = tf_idf * tf_idf.T\n",
        "      for x in range(0, pairwise_similarity.shape[0]):\n",
        "        for y in range(0, pairwise_similarity.shape[1]):\n",
        "          if pairwise_similarity[x, y] > .90 and not x == y and not [y, x] in matches:\n",
        "            matches.append([x, y])\n",
        "\n",
        "      if len(matches) > 0:\n",
        "        matched_rows_df = temp_df.iloc[[value for i in matches for value in i], ]\n",
        "        match_indices = matched_rows_df.index\n",
        "\n",
        "        phrase_index_in_phrases = [i for i, value in enumerate(paper_data_dict[paper][0]) if value == (phrase, count)][0]\n",
        "        paper_data_dict[paper][0][phrase_index_in_phrases] = (phrase, 1)\n",
        "        paper_df = paper_df.drop([match for match in match_indices[1:]])\n",
        "        matches = []\n",
        "  \n",
        "    print(f'\\rsearched duplicates in {paper}: {i+1} of {search_length}', end='')\n",
        "\n",
        "  catch_phrases_remove.extend([headline_counter[0] for headline_counter in paper_data_dict[paper][0] if headline_counter[1] > 1])\n",
        "  print(f'\\nremoving duplicates...', end='\\n\\n')\n",
        "  \n",
        "  for phrase in catch_phrases_remove:\n",
        "    if not phrase == '' or not phrase:\n",
        "      paper_df.loc[paper_df['Headline'] == phrase, 'Headline'] = ''\n",
        "\n",
        "  return paper_df['Headline']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjgHLfWauG9q",
        "colab_type": "text"
      },
      "source": [
        "### Cleaner – Lower All"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCw3YrKRxEpQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lower_clean_all(paper):\n",
        "  \"\"\"Cleaner function for Star Tribune rows.\"\"\"\n",
        "\n",
        "  EPU.loc[EPU['Newspaper'] == paper, 'Headline'] = duplicates_clean_lower(paper)\n",
        "  print(f'completed duplicates clean...')\n",
        "  print(f'final clean for paper: {paper}...', end='\\n\\n')\n",
        "  print('–––––––––––––––––––––––', end='\\n\\n')\n",
        "  \n",
        "  paper_data_dict = build_headline_counter_dict()\n",
        "  final_clean = {headline_counter[0]: headline_counter[1] for headline_counter in paper_data_dict[paper][0] if headline_counter[1] > 1}\n",
        "\n",
        "  drop_list = []\n",
        "  for phrase, count in final_clean.items():\n",
        "    if phrase == '':\n",
        "      rows = list(EPU.loc[EPU['Headline'] == phrase].index)\n",
        "      drop_list.extend(rows)\n",
        "    \n",
        "    elif count > 1:\n",
        "      rows = list(EPU.loc[EPU['Headline'] == phrase].index)[1:]\n",
        "      drop_list.extend(rows)\n",
        "      \n",
        "  drop_list.extend(list(EPU.loc[pd.isnull(EPU['Headline'])].index))\n",
        "  frame_out = EPU[~EPU.index.isin(drop_list)]\n",
        "  return frame_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkHwWaYSxGsF",
        "colab_type": "text"
      },
      "source": [
        "### Run Lower-Case Cleaner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pX40aGLywqyZ",
        "outputId": "13546081-f331-49eb-d085-5d490ca3771b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for paper in papers:\n",
        "  EPU = lower_clean_all(paper)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "searched duplicates in The Washington Post: 2618 of 2618\n",
            "removing duplicates...\n",
            "\n",
            "completed duplicates clean...\n",
            "final clean for paper: The Washington Post...\n",
            "\n",
            "–––––––––––––––––––––––\n",
            "\n",
            "searched duplicates in Pittsburgh Post-Gazette (Pennsylvania): 1054 of 1054\n",
            "removing duplicates...\n",
            "\n",
            "completed duplicates clean...\n",
            "final clean for paper: Pittsburgh Post-Gazette (Pennsylvania)...\n",
            "\n",
            "–––––––––––––––––––––––\n",
            "\n",
            "searched duplicates in The Atlanta Journal-Constitution: 599 of 599\n",
            "removing duplicates...\n",
            "\n",
            "completed duplicates clean...\n",
            "final clean for paper: The Atlanta Journal-Constitution...\n",
            "\n",
            "–––––––––––––––––––––––\n",
            "\n",
            "searched duplicates in St. Louis Post-Dispatch (Missouri): 1181 of 1181\n",
            "removing duplicates...\n",
            "\n",
            "completed duplicates clean...\n",
            "final clean for paper: St. Louis Post-Dispatch (Missouri)...\n",
            "\n",
            "–––––––––––––––––––––––\n",
            "\n",
            "searched duplicates in USA Today: 907 of 907\n",
            "removing duplicates...\n",
            "\n",
            "completed duplicates clean...\n",
            "final clean for paper: USA Today...\n",
            "\n",
            "–––––––––––––––––––––––\n",
            "\n",
            "searched duplicates in Star Tribune (Minneapolis, MN): 325 of 325\n",
            "removing duplicates...\n",
            "\n",
            "completed duplicates clean...\n",
            "final clean for paper: Star Tribune (Minneapolis, MN)...\n",
            "\n",
            "–––––––––––––––––––––––\n",
            "\n",
            "searched duplicates in The Philadelphia Inquirer (Pennsylvania): 1008 of 1008\n",
            "removing duplicates...\n",
            "\n",
            "completed duplicates clean...\n",
            "final clean for paper: The Philadelphia Inquirer (Pennsylvania)...\n",
            "\n",
            "–––––––––––––––––––––––\n",
            "\n",
            "searched duplicates in St. Petersburg Times (Florida): 634 of 634\n",
            "removing duplicates...\n",
            "\n",
            "completed duplicates clean...\n",
            "final clean for paper: St. Petersburg Times (Florida)...\n",
            "\n",
            "–––––––––––––––––––––––\n",
            "\n",
            "searched duplicates in The Orange County Register (California): 699 of 699\n",
            "removing duplicates...\n",
            "\n",
            "completed duplicates clean...\n",
            "final clean for paper: The Orange County Register (California)...\n",
            "\n",
            "–––––––––––––––––––––––\n",
            "\n",
            "searched duplicates in Tampa Bay Times: 195 of 195\n",
            "removing duplicates...\n",
            "\n",
            "completed duplicates clean...\n",
            "final clean for paper: Tampa Bay Times...\n",
            "\n",
            "–––––––––––––––––––––––\n",
            "\n",
            "searched duplicates in The New York Post: 211 of 211\n",
            "removing duplicates...\n",
            "\n",
            "completed duplicates clean...\n",
            "final clean for paper: The New York Post...\n",
            "\n",
            "–––––––––––––––––––––––\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lK8i6MvAWsoW",
        "colab_type": "code",
        "outputId": "58b1b75e-17bb-4028-ddbb-17a66e6bf3f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "EPU.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(299953, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9UiXaHuOYivz"
      },
      "source": [
        "#General Cleaning\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzk2u91z9uqb",
        "colab_type": "text"
      },
      "source": [
        "#### Define Contraction Mapper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BA5jJKR89ub2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "contraction_mapping = { \n",
        "    \"ain't\": \"is not\", \n",
        "    \"aren't\": \"are not\", \n",
        "    \"can't\": \"cannot\", \n",
        "    \"'cause\": \"because\", \n",
        "    \"could've\": \"could have\", \n",
        "    \"couldn't\": \"could not\",\n",
        "    \"didn't\": \"did not\", \n",
        "    \"doesn't\": \"does not\", \n",
        "    \"don't\": \"do not\", \n",
        "    \"hadn't\": \"had not\", \n",
        "    \"hasn't\": \"has not\", \n",
        "    \"haven't\": \"have not\",\n",
        "    \"he'd\": \"he would\", \n",
        "    \"he'll\": \"he will\", \n",
        "    \"he's\": \"he is\", \n",
        "    \"how'd\": \"how did\", \n",
        "    \"how'd'y\": \"how do you\", \n",
        "    \"how'll\": \"how will\", \n",
        "    \"how's\": \"how is\",\n",
        "    \"I'd\": \"I would\", \n",
        "    \"I'd've\": \"I would have\", \n",
        "    \"I'll\": \"I will\", \n",
        "    \"I'll've\": \"I will have\", \n",
        "    \"I'm\": \"I am\", \n",
        "    \"I've\": \"I have\", \n",
        "    \"i'd\": \"i would\",\n",
        "    \"i'd've\": \"i would have\", \n",
        "    \"i'll\": \"i will\", \n",
        "    \"i'll've\": \"i will have\", \n",
        "    \"i'm\": \"i am\", \n",
        "    \"i've\": \"i have\", \n",
        "    \"isn't\": \"is not\", \n",
        "    \"it'd\": \"it would\",\n",
        "    \"it'd've\": \"it would have\", \n",
        "    \"it'll\": \"it will\", \n",
        "    \"it'll've\": \"it will have\", \n",
        "    \"it's\": \"it is\", \n",
        "    \"let's\": \"let us\", \n",
        "    \"ma'am\": \"madam\",\n",
        "    \"mayn't\": \"may not\", \n",
        "    \"might've\": \"might have\", \n",
        "    \"mightn't\": \"might not\", \n",
        "    \"mightn't've\": \"might not have\", \n",
        "    \"must've\": \"must have\",\n",
        "    \"mustn't\": \"must not\", \n",
        "    \"mustn't've\": \"must not have\", \n",
        "    \"needn't\": \"need not\", \n",
        "    \"needn't've\": \"need not have\", \n",
        "    \"o'clock\": \"of the clock\",\n",
        "    \"oughtn't\": \"ought not\", \n",
        "    \"oughtn't've\": \"ought not have\", \n",
        "    \"shan't\": \"shall not\", \n",
        "    \"sha'n't\": \"shall not\", \n",
        "    \"shan't've\": \"shall not have\",\n",
        "    \"she'd\": \"she would\", \n",
        "    \"she'd've\": \"she would have\", \n",
        "    \"she'll\": \"she will\", \n",
        "    \"she'll've\": \"she will have\", \n",
        "    \"she's\": \"she is\",\n",
        "    \"should've\": \"should have\", \n",
        "    \"shouldn't\": \"should not\", \n",
        "    \"shouldn't've\": \"should not have\", \n",
        "    \"so've\": \"so have\", \n",
        "    \"so's\": \"so as\",\n",
        "    \"this's\": \"this is\", \n",
        "    \"that'd\": \"that would\", \n",
        "    \"that'd've\": \"that would have\", \n",
        "    \"that's\": \"that is\", \n",
        "    \"there'd\": \"there would\",\n",
        "    \"there'd've\": \"there would have\", \n",
        "    \"there's\": \"there is\", \n",
        "    \"here's\": \"here is\", \n",
        "    \"they'd\": \"they would\", \n",
        "    \"they'd've\": \"they would have\",\n",
        "    \"they'll\": \"they will\", \n",
        "    \"they'll've\": \"they will have\", \n",
        "    \"they're\": \"they are\", \n",
        "    \"they've\": \"they have\", \n",
        "    \"to've\": \"to have\",\n",
        "    \"wasn't\": \"was not\", \n",
        "    \"we'd\": \"we would\", \n",
        "    \"we'd've\": \"we would have\", \n",
        "    \"we'll\": \"we will\", \n",
        "    \"we'll've\": \"we will have\", \n",
        "    \"we're\": \"we are\",\n",
        "    \"we've\": \"we have\", \n",
        "    \"weren't\": \"were not\", \n",
        "    \"what'll\": \"what will\", \n",
        "    \"what'll've\": \"what will have\", \n",
        "    \"what're\": \"what are\",\n",
        "    \"what's\": \"what is\", \n",
        "    \"what've\": \"what have\", \n",
        "    \"when's\": \"when is\", \n",
        "    \"when've\": \"when have\", \n",
        "    \"where'd\": \"where did\", \n",
        "    \"where's\": \"where is\",\n",
        "    \"where've\": \"where have\", \n",
        "    \"who'll\": \"who will\", \n",
        "    \"who'll've\": \"who will have\", \n",
        "    \"who's\": \"who is\", \n",
        "    \"who've\": \"who have\",\n",
        "    \"why's\": \"why is\", \n",
        "    \"why've\": \"why have\", \n",
        "    \"will've\": \"will have\", \n",
        "    \"won't\": \"will not\", \n",
        "    \"won't've\": \"will not have\",\n",
        "    \"would've\": \"would have\", \n",
        "    \"wouldn't\": \"would not\", \n",
        "    \"wouldn't've\": \"would not have\", \n",
        "    \"y'all\": \"you all\",\n",
        "    \"y'all'd\": \"you all would\", \n",
        "    \"y'all'd've\": \"you all would have\", \n",
        "    \"y'all're\": \"you all are\", \n",
        "    \"y'all've\": \"you all have\",\n",
        "    \"you'd\": \"you would\", \n",
        "    \"you'd've\": \"you would have\", \n",
        "    \"you'll\": \"you will\", \n",
        "    \"you'll've\": \"you will have\",\n",
        "    \"you're\": \"you are\", \n",
        "    \"you've\": \"you have\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1x6_HFGSeaKL",
        "colab_type": "text"
      },
      "source": [
        "#### Operator Functions for Text Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-A6yZN9JbkE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cleaner_passover(text):\n",
        "  \"\"\"Operator function for initial text cleaning.\"\"\"\n",
        "  \n",
        "  punct_re_string = '|'.join('\\\\' + char for char in punctuation)\n",
        "  punct_re_string = r'['+punct_re_string+']'\n",
        "  hyphen_unicode_list = '[\\u002D\\u058A\\u05BE\\u1400\\u1806\\u2010-\\u2015\\u2E17\\u2E1A\\u2E3A\\u2E3B\\u2E40\\u301C\\u3030\\u30A0\\uFE31\\uFE32\\uFE58\\uFE63\\uFF0D]'\n",
        "\n",
        "  text = text.lower()\n",
        "  text = unidecode.unidecode(text)\n",
        "  \n",
        "  text = ' '.join([contraction_mapping[word] if word in contraction_mapping else word for word in text.split(' ')])  \n",
        "  text = text.replace('&', ' and ')\n",
        "  text = text.replace('@', ' at ')\n",
        "  text = re.sub(r'\\s' + re.escape(hyphen_unicode_list) + '\\s', '', text)\n",
        "  text = re.sub(re.escape(hyphen_unicode_list), '', text)\n",
        "  text = text.replace(\"'\", '')\n",
        "  text = text.replace(\",\", '')\n",
        "  text = text.replace(\".\", '')\n",
        "  text = re.sub(punct_re_string, ' ', text)\n",
        "\n",
        "  text = re.sub(r'\\w*\\d+\\w*', '', text)\n",
        "  text = re.sub(r'\\d', '', text)\n",
        "  \n",
        "  text = re.sub('\\s\\s+' , ' ', text)\n",
        "  return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZq1bEX_4gx-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cleaning_handler(row, df_length):\n",
        "  \"\"\"Handler for cleaning functions.\"\"\"\n",
        "  \n",
        "  row['Article'] = str(row['Article'])\n",
        "  row['Headline'] = str(row['Headline'])\n",
        "\n",
        "  row['Article'] = re.sub(r'https?:\\/\\/[^\\s]*\\s', '', row['Article'])\n",
        "  row['Article'] = re.sub(r'www[^\\s]*\\s', '', row['Article'])\n",
        "  row['Article'] = re.sub(r'\\s[^\\s]*.com[\\s\\.]', '', row['Article'])\n",
        "  row['Article'] = BeautifulSoup(row['Article']).text\n",
        "  row['Article'] = re.sub(r'\\n', r' ', row['Article'])\n",
        "\n",
        "  row['Headline'] = re.sub(r'https?:\\/\\/[^\\s]*\\s', '', row['Headline'])\n",
        "  row['Headline'] = re.sub(r'www[^\\s]*\\s', '', row['Headline'])\n",
        "  row['Headline'] = re.sub(r'\\s[^\\s]*.com[\\s\\.]', '', row['Headline'])\n",
        "  row['Headline'] = BeautifulSoup(row['Headline']).text\n",
        "  row['Headline'] = re.sub(r'\\n', r' ', row['Headline'])\n",
        "  \n",
        "  row['Article'] = cleaner_passover(row['Article'])\n",
        "  row['Headline'] = cleaner_passover(row['Headline'])\n",
        "  \n",
        "  print(f'\\rcompleted: {row.name + 1} of {df_length}', end='')\n",
        "  return row"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkSS_IKYdsqY",
        "colab_type": "text"
      },
      "source": [
        "#### Apply General Cleaner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJbhzfvgdtDx",
        "colab_type": "code",
        "outputId": "6793ab85-fe07-4b17-d595-0db0377c8ec3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "EPU = EPU.reset_index()\n",
        "EPU = EPU.drop('index', axis=1)\n",
        "EPU_cleaned = EPU.apply(lambda row: cleaning_handler(row, len(EPU)), axis=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "completed: 299953 of 299953"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlBXo_yObpy9",
        "colab_type": "text"
      },
      "source": [
        "### Define & Remove Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1pp7afI-yaCU",
        "colab": {}
      },
      "source": [
        "stop_words = set([re.sub(r'\\W', '', word) for word in nlp.Defaults.stop_words])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04hv2oL1b_c7",
        "colab_type": "text"
      },
      "source": [
        "#### Identify Words That Appear Seldomly (Articles)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1P4-w8FzbmiG",
        "colab_type": "code",
        "outputId": "041682a9-6634-481b-80f1-851c910f2de4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        }
      },
      "source": [
        "vect_count = CountVectorizer()\n",
        "\n",
        "word_counts = vect_count.fit_transform(EPU_cleaned['Article'].astype(str))\n",
        "sum_words = word_counts.sum(axis=0)\n",
        "\n",
        "frequencies = [(word, sum_words[0, idx]) for word, idx in vect_count.vocabulary_.items() if not word in stop_words]\n",
        "frequencies = sorted(frequencies, key=lambda x: x[1], reverse=True)\n",
        "print(f'Total words: {len(frequencies)}')\n",
        "\n",
        "low_count_words_article = [word for word, freq in frequencies if freq < 60]\n",
        "single_character_words_article = [word for word, freq in frequencies if len(word) == 1]\n",
        "\n",
        "print(f'Count of words occuring less than 60 times: {len(low_count_words_article)}')\n",
        "print(f'Remaining words: {len(frequencies) - len(low_count_words_article)} \\n')\n",
        "\n",
        "common_words = frequencies[:20]\n",
        "for word, frequency in common_words:\n",
        "    print(word, frequency)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total words: 508657\n",
            "Count of words occuring less than 60 times: 458646\n",
            "Remaining words: 50011 \n",
            "\n",
            "said 1647581\n",
            "year 572948\n",
            "new 556554\n",
            "percent 525136\n",
            "people 436461\n",
            "years 420477\n",
            "state 408316\n",
            "million 336585\n",
            "economic 332319\n",
            "time 330871\n",
            "president 323103\n",
            "city 300431\n",
            "government 274307\n",
            "economy 270818\n",
            "tax 264773\n",
            "like 262169\n",
            "states 260966\n",
            "says 244703\n",
            "business 235188\n",
            "county 234270\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5_5ud4ZrU_Xj"
      },
      "source": [
        "#### Identify Words That Appear Seldomly (Headlines)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a80155f7-13d2-42fc-b237-d131fd9f0525",
        "id": "qIc9PXrcU_Xn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        }
      },
      "source": [
        "vect_count = CountVectorizer()\n",
        "\n",
        "word_counts = vect_count.fit_transform(EPU_cleaned['Headline'].astype(str))\n",
        "sum_words = word_counts.sum(axis=0)\n",
        "\n",
        "frequencies = [(word, sum_words[0, idx]) for word, idx in vect_count.vocabulary_.items() if not word in stop_words]\n",
        "frequencies = sorted(frequencies, key=lambda x: x[1], reverse=True)\n",
        "print(f'Total words: {len(frequencies)}')\n",
        "\n",
        "low_count_words_headline = [word for word, freq in frequencies if freq < 5]\n",
        "single_character_words_headline = [word for word, freq in frequencies if (len(word) == 1 and not word == 'a')]\n",
        "\n",
        "print(f'Count of words occuring less than 5 times: {len(low_count_words_headline)} \\n')\n",
        "print(f'Remaining words: {len(frequencies) - len(low_count_words_headline)} \\n')\n",
        "\n",
        "common_words = frequencies[:20]\n",
        "for word, frequency in common_words:\n",
        "    print(word, frequency)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total words: 59841\n",
            "Count of words occuring less than 5 times: 37691 \n",
            "\n",
            "Remaining words: 22150 \n",
            "\n",
            "new 15097\n",
            "tax 7708\n",
            "economy 7603\n",
            "obama 7258\n",
            "says 7035\n",
            "state 6695\n",
            "plan 6353\n",
            "jobs 6043\n",
            "city 5995\n",
            "big 5437\n",
            "economic 5056\n",
            "year 4973\n",
            "business 4749\n",
            "time 4568\n",
            "trump 4394\n",
            "budget 4376\n",
            "help 4352\n",
            "home 4153\n",
            "deal 4141\n",
            "gop 4133\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qq4tXs220gMf",
        "colab_type": "text"
      },
      "source": [
        "### Copy EPU Frame & Minimise via Trimming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWBSPu110f7C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPU_raw = EPU_cleaned.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQ_Y13pS2Eju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def article_trimmer(article):\n",
        "  \"\"\"Trim articles to 70 tokens.\"\"\"\n",
        "  \n",
        "  article = ' '.join([word for i, word in enumerate(article.split()) if i <= 80])\n",
        "  return article"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6pvIMhB1zCG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPU_raw['Article'] = EPU_raw['Article'].apply(lambda article: article_trimmer(article))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOKvQ4Hj0s3W",
        "colab_type": "code",
        "outputId": "45adbc4a-e542-47e8-d319-7c7d147c48d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        }
      },
      "source": [
        "vect_count = CountVectorizer()\n",
        "\n",
        "word_counts = vect_count.fit_transform(EPU_raw['Article'].astype(str))\n",
        "sum_words = word_counts.sum(axis=0)\n",
        "\n",
        "frequencies = [(word, sum_words[0, idx]) for word, idx in vect_count.vocabulary_.items() if not word in stop_words]\n",
        "frequencies = sorted(frequencies, key=lambda x: x[1], reverse=True)\n",
        "print(f'Total words: {len(frequencies)}')\n",
        "\n",
        "low_count_words_article_raw = [word for word, freq in frequencies if freq < 10]\n",
        "single_character_words_article_raw = [word for word, freq in frequencies if len(word) == 1]\n",
        "\n",
        "print(f'Count of words occuring less than 10 times: {len(low_count_words_article_raw)}')\n",
        "print(f'Remaining words: {len(frequencies) - len(low_count_words_article)} \\n')\n",
        "\n",
        "common_words = frequencies[:20]\n",
        "for word, frequency in common_words:\n",
        "    print(word, frequency)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total words: 152737\n",
            "Count of words occuring less than 10 times: 113064\n",
            "Remaining words: 39673 \n",
            "\n",
            "said 81421\n",
            "new 78468\n",
            "year 75134\n",
            "president 56135\n",
            "years 54262\n",
            "state 51117\n",
            "percent 50007\n",
            "economic 44443\n",
            "city 42603\n",
            "economy 39448\n",
            "million 37882\n",
            "county 36580\n",
            "time 35808\n",
            "people 34095\n",
            "week 32397\n",
            "states 29503\n",
            "government 28622\n",
            "federal 28231\n",
            "obama 28059\n",
            "tax 27151\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "em2OH3Ldb_3c",
        "colab_type": "text"
      },
      "source": [
        "#### Combine Stopword Sublists"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0he6H0UIcAOY",
        "colab_type": "code",
        "outputId": "c7b1a764-5236-487f-fdd2-b3857375951f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "custom_words_article = ['said', 'a']\n",
        "stop_words_headline = set(low_count_words_headline + single_character_words_headline)\n",
        "\n",
        "combined_custom_stopwords_article = set(low_count_words_article + custom_words_article)\n",
        "combined_custom_stopwords_article_raw = set(low_count_words_article_raw + custom_words_article)\n",
        "\n",
        "stop_words_article = stop_words.copy()\n",
        "stop_words_article.update(combined_custom_stopwords_article)\n",
        "\n",
        "stop_words_article_raw = stop_words.copy()\n",
        "stop_words_article_raw.update(combined_custom_stopwords_article_raw)\n",
        "\n",
        "print(f'Count stop words article: {len(stop_words_article)}')\n",
        "print(f'Count stop words article raw: {len(stop_words_article_raw)}')\n",
        "print(f'Count stop words headline: {len(stop_words_headline)}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count stop words article: 458958\n",
            "Count stop words article raw: 113376\n",
            "Count stop words headline: 37691\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPwIvtzXf1zT",
        "colab_type": "text"
      },
      "source": [
        "#### Remove Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQnIadjwf1mz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPU_cleaned['Article'] = EPU_cleaned['Article'].apply(lambda text: ' '.join(word for word in str(text).split() if word not in stop_words_article))\n",
        "EPU_raw['Article'] = EPU_raw['Article'].apply(lambda text: ' '.join(word for word in str(text).split() if word not in stop_words_article_raw))\n",
        "\n",
        "EPU_cleaned['Headline'] = EPU_cleaned['Headline'].apply(lambda text: ' '.join(word for word in str(text).split() if word not in stop_words_headline))\n",
        "EPU_raw['Headline'] = EPU_raw['Headline'].apply(lambda text: ' '.join(word for word in str(text).split() if word not in stop_words_headline))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "azqMGDvyoRFy"
      },
      "source": [
        "### Trim Short Headlines (once more after cleaning)\n",
        "***\n",
        "\n",
        "##### Remove headlines with less than 4 words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Lu1-nA_YoRF1",
        "colab": {}
      },
      "source": [
        "EPU_cleaned['Headline'] = EPU_cleaned['Headline'].apply(lambda headline: np.nan if not len(str(headline).split()) >= 4 else headline)\n",
        "EPU_raw['Headline'] = EPU_raw['Headline'].apply(lambda headline: np.nan if not len(str(headline).split()) >= 4 else headline)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ti5X0q7A1zIf",
        "colab_type": "text"
      },
      "source": [
        "### Trim Short Articles (once more after cleaning)\n",
        "***\n",
        "\n",
        "##### Remove Articles with less than 30 or 10 words, respectively"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kX20DTSa1y9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPU_cleaned['Article'] = EPU_cleaned['Article'].apply(lambda article: np.nan if not len(str(article).split()) >= 30 else article)\n",
        "EPU_raw['Article'] = EPU_raw['Article'].apply(lambda article: np.nan if not len(str(article).split()) >= 10 else article)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYUJjLlM55OK",
        "colab_type": "text"
      },
      "source": [
        "#### Final `Null` Value Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LPnvtWc55if",
        "colab_type": "code",
        "outputId": "c510d520-e3e2-42ee-ec32-329d80895d0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "print(EPU_cleaned.isnull().sum(axis = 0), '\\n\\n', '... dropping rows with `null` in `Headline` or `Article`.')\n",
        "EPU_cleaned = EPU_cleaned.dropna(subset=['Headline', 'Article'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Newspaper       0\n",
            "Date            3\n",
            "Headline     4956\n",
            "Article       153\n",
            "Label           0\n",
            "Prefix          0\n",
            "dtype: int64 \n",
            "\n",
            " ... dropping rows with `null` in `Headline` or `Article`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h89WTdOL5_KZ",
        "colab_type": "code",
        "outputId": "911d08f3-3014-4483-c80a-cf0674325bb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "print(EPU_raw.isnull().sum(axis = 0), '\\n\\n', '... dropping rows with `null` in `Headline` or `Article`.')\n",
        "EPU_raw = EPU_raw.dropna(subset=['Headline', 'Article'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Newspaper       0\n",
            "Date            3\n",
            "Headline     4956\n",
            "Article         8\n",
            "Label           0\n",
            "Prefix          0\n",
            "dtype: int64 \n",
            "\n",
            " ... dropping rows with `null` in `Headline` or `Article`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SiU3Q6styFTL"
      },
      "source": [
        "### Identify Avg. `Article` & `Headline` Lengths for Trimming "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "njWXzyNSyFTP",
        "colab": {}
      },
      "source": [
        "article_lengths = EPU_cleaned.apply(lambda row: len(row['Article'].split()), axis=1)\n",
        "article_length_trimmed = EPU_raw.apply(lambda row: len(row['Article'].split()), axis=1)\n",
        "headline_lengths = EPU_cleaned.apply(lambda row: len(row['Headline'].split()), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f96037f7-5523-4cc3-b4e2-a56e292d24e1",
        "id": "1TChn2UsyFTS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(18, 6))\n",
        "sns.distplot(article_lengths, ax=ax[0])\n",
        "sns.distplot(article_length_trimmed, ax=ax[1])\n",
        "sns.distplot(headline_lengths, ax=ax[2])\n",
        "fig.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABCoAAAFlCAYAAAAtYwnUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIiIiIiIiEjJ+P8BPX8g+MsFUGQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1296x432 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0ac68487-d012-4aca-ab82-4971d5fc2cc1",
        "id": "N1d5y3GVyFTV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "print(f'median article length is: {int(article_lengths.median())} words')\n",
        "print(f'median article length (trimmed) is: {int(article_length_trimmed.median())} words')\n",
        "print(f'median headline length is: {int(headline_lengths.median())} words')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "median article length is: 358 words\n",
            "median article length (trimmed) is: 44 words\n",
            "median headline length is: 8 words\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llsJvgpK3iwP",
        "colab_type": "code",
        "outputId": "12e069ec-1ff3-4117-bf75-787233d86bea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "count_article = 0\n",
        "count_article_trimmed = 0\n",
        "count_headline = 0\n",
        "\n",
        "for i in EPU_cleaned['Article']:\n",
        "    if(len(i.split()) <= 550):\n",
        "        count_article += 1\n",
        "\n",
        "for i in EPU_raw['Article']:\n",
        "    if(len(i.split()) <= 50):\n",
        "        count_article_trimmed += 1\n",
        "\n",
        "for i in EPU_cleaned['Headline']:\n",
        "    if(len(i.split()) <= 20):\n",
        "        count_headline += 1\n",
        "\n",
        "print(f'Proportion of Articles under 550 words in length: {round(count_article / len(EPU_cleaned), 2)}')\n",
        "print(f'Proportion of Articles (trimmed) under 50 words in length: {round(count_article_trimmed / len(EPU_raw), 2)}')\n",
        "print(f'Proportion of Headline under 20 words in length: {round(count_headline / len(EPU_cleaned), 2)}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Proportion of Articles under 550 words in length: 0.83\n",
            "Proportion of Articles (trimmed) under 50 words in length: 0.93\n",
            "Proportion of Headline under 20 words in length: 0.94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pshoxO8myFTX",
        "colab": {}
      },
      "source": [
        "max_length_article = 550\n",
        "max_length_article_trimmed = 50\n",
        "max_length_headline = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7dCsVXG5_OE",
        "colab_type": "text"
      },
      "source": [
        "#### Trim EPU Data Frame to Rows w/ Headline of 20 Words or Less"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpHMRxiA5_Ah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPU_cleaned['headline_length'] = EPU_cleaned.apply(lambda row: len(row['Headline'].split()), axis=1)\n",
        "EPU_raw['headline_length'] = EPU_raw.apply(lambda row: len(row['Headline'].split()), axis=1)\n",
        "\n",
        "EPU_trimmed = EPU_cleaned.loc[EPU_cleaned['headline_length'] <= max_length_headline]\n",
        "EPU_trimmed_trimmed = EPU_raw.loc[EPU_raw['headline_length'] <= max_length_headline]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9V0gI0uOZVk1",
        "colab_type": "text"
      },
      "source": [
        "### Add `START` & `END` Tokens to Headlines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eV-LlO-zZVWD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPU_trimmed['Headline'] = EPU_trimmed['Headline'].apply(lambda headline : 'tokenstart ' + headline + ' tokenend')\n",
        "EPU_trimmed_trimmed['Headline'] = EPU_trimmed_trimmed['Headline'].apply(lambda headline : 'tokenstart ' + headline + ' tokenend')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZvRHiUG6jsB",
        "colab_type": "text"
      },
      "source": [
        "### Checkpoint Data Save"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fHQwnXFT2BBm",
        "colab": {}
      },
      "source": [
        "EPU_trimmed.to_csv('EPU_checkpoint_full_new.csv')\n",
        "EPU_trimmed_trimmed.to_csv('EPU_checkpoint_trimmed_new.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJCY2BMD2CdX",
        "colab_type": "text"
      },
      "source": [
        "# Language Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbhbEq9-9A7Z",
        "colab_type": "text"
      },
      "source": [
        "## Test / Train Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8vUqu9N7NpW",
        "colab_type": "text"
      },
      "source": [
        "### Load Checkpoint Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKAylwXKg2xq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/gdrive/My Drive/colab_notebooks/information_systems/data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keAslEDvfTPo",
        "colab_type": "text"
      },
      "source": [
        "##### Full Article Lengths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWYgjJC-fTB5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPU_checkpoint = pd.read_csv('EPU_checkpoint_full_new.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EefZgYg88oPh",
        "colab_type": "text"
      },
      "source": [
        "### Slice Down to `Article` & `Headline` Columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smBA4gf68n_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPU_seq = EPU_checkpoint[['Article', 'Headline', 'Label']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wg73uDwB6Ckt",
        "colab_type": "text"
      },
      "source": [
        "#### Split Test / Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdT_5myB6DBB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPU_train, EPU_test = train_test_split(EPU_seq, test_size=.10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuSJJckc6yL3",
        "colab_type": "code",
        "outputId": "f1c3ef04-55c3-47a6-986a-34f19d8a3d7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(EPU_train.shape)\n",
        "print(EPU_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(250388, 3)\n",
            "(27821, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81HTYDq67tTo",
        "colab_type": "text"
      },
      "source": [
        "## Tokeniser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mm76hVtEAdE7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_length_article = 550\n",
        "max_length_headline = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQ8VXQ2p6LQT",
        "colab_type": "text"
      },
      "source": [
        "### Run Tokenisers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHUSxZ6y7tIg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "article_tokeniser = Tokenizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCCQEkLNHNXN",
        "colab_type": "code",
        "outputId": "ecb580ca-b768-4a22-ab4d-a47ec37b0b0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "article_tokeniser.fit_on_texts(list(EPU_train['Article']))\n",
        "train_sequences_article = article_tokeniser.texts_to_sequences(EPU_train['Article'])\n",
        "test_sequences_article = article_tokeniser.texts_to_sequences(EPU_test['Article'])\n",
        "\n",
        "train_sequences_article = pad_sequences(train_sequences_article, maxlen=max_length_article, padding='post')\n",
        "test_sequences_article = pad_sequences(test_sequences_article, maxlen=max_length_article, padding='post')\n",
        "\n",
        "article_vocabulary = article_tokeniser.word_index\n",
        "article_vocabulary_size = len(article_tokeniser.word_index) + 1\n",
        "print(f'article vocabulary size: {article_vocabulary_size}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "article vocabulary size: 50739\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNrUgWkCkA_D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "headline_tokeniser = Tokenizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdMzieGIMZlg",
        "colab_type": "code",
        "outputId": "f3d56bff-e013-497c-8be4-2c73c9877e52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "headline_tokeniser.fit_on_texts(list(EPU_train['Headline']))\n",
        "train_sequences_headline = headline_tokeniser.texts_to_sequences(EPU_train['Headline'])\n",
        "test_sequences_headline = headline_tokeniser.texts_to_sequences(EPU_test['Headline'])\n",
        "\n",
        "train_sequences_headline = pad_sequences(train_sequences_headline, maxlen=max_length_headline, padding='post')\n",
        "test_sequences_headline = pad_sequences(test_sequences_headline, maxlen=max_length_headline, padding='post')\n",
        "\n",
        "headline_vocabulary = headline_tokeniser.word_index\n",
        "headline_vocabulary_size = len(headline_tokeniser.word_index) + 1\n",
        "print(f'headline vocabulary size: {headline_vocabulary_size}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "headline vocabulary size: 22487\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmkJ4VqaIe3O",
        "colab_type": "text"
      },
      "source": [
        "### Pickle `Tokeniser` Objects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1dll8vyIesJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/gdrive/My Drive/colab_notebooks/information_systems/data/pickled_tokenisers')\n",
        "\n",
        "### Article_trimmed\n",
        "\n",
        "with open('tokenizer_article.pkl', 'wb') as article_tokeniser_out:\n",
        "    pickle.dump(article_tokeniser, article_tokeniser_out, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "with open('train_sequences_article.pkl', 'wb') as train_sequences_article_out:\n",
        "    pickle.dump(train_sequences_article, train_sequences_article_out, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    \n",
        "with open('test_sequences_article.pkl', 'wb') as test_sequences_article_out:\n",
        "    pickle.dump(test_sequences_article, test_sequences_article_out, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "### Headline\n",
        "\n",
        "with open('tokenizer_headline.pkl', 'wb') as headline_tokeniser_out:\n",
        "    pickle.dump(headline_tokeniser, headline_tokeniser_out, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "with open('train_sequences_headline.pkl', 'wb') as train_sequences_headline_out:\n",
        "    pickle.dump(train_sequences_headline, train_sequences_headline_out, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "with open('test_sequences_headline.pkl', 'wb') as test_sequences_headline_out:\n",
        "    pickle.dump(test_sequences_headline, test_sequences_headline_out, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0_jIA7uIjtk",
        "colab_type": "text"
      },
      "source": [
        "### Load `Tokeniser` Pickle Objects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REGf1MmjIjYw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/gdrive/My Drive/colab_notebooks/information_systems/data/pickled_tokenisers')\n",
        "\n",
        "with open('tokenizer_article.pkl', 'rb') as article_tokeniser_in:\n",
        "    article_tokeniser = pickle.load(article_tokeniser_in)\n",
        "    article_vocabulary = article_tokeniser.word_index\n",
        "    article_vocabulary_size = len(article_tokeniser.word_index) + 1\n",
        "\n",
        "with open('train_sequences_article.pkl', 'rb') as train_sequences_article_in:\n",
        "    train_sequences_article = pickle.load(train_sequences_article_in)\n",
        "\n",
        "with open('test_sequences_article.pkl', 'rb') as test_sequences_article_in:\n",
        "    test_sequences_article = pickle.load(test_sequences_article_in)\n",
        "\n",
        "### Headline\n",
        "\n",
        "with open('tokenizer_headline.pkl', 'rb') as headline_tokeniser_in:\n",
        "    headline_tokeniser = pickle.load(headline_tokeniser_in)\n",
        "    headline_vocabulary = headline_tokeniser.word_index\n",
        "    headline_vocabulary_size = len(headline_tokeniser.word_index) + 1\n",
        "\n",
        "with open('train_sequences_headline.pkl', 'rb') as train_sequences_headline_in:\n",
        "    train_sequences_headline = pickle.load(train_sequences_headline_in)\n",
        "\n",
        "with open('test_sequences_headline.pkl', 'rb') as test_sequences_headline_in:\n",
        "    test_sequences_headline = pickle.load(test_sequences_headline_in)\n",
        "\n",
        "os.chdir('/gdrive/My Drive/colab_notebooks/information_systems/data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGGv0EvDTcTW",
        "colab_type": "text"
      },
      "source": [
        "## Pre-Trained Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "E9oepqWrLOmY"
      },
      "source": [
        "### GLoVe Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t1PhhDX5LOma",
        "colab": {}
      },
      "source": [
        "embeddings_index = {}\n",
        "with open('GLoVe_embeddings/glove.6B.300d.txt') as glove_in:\n",
        "    for line in glove_in:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, 'f', sep=' ')\n",
        "        embeddings_index[word] = coefs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aT_mlADf8Tto",
        "colab_type": "text"
      },
      "source": [
        "#### Prepare Embedding Matrix – Article"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RPvaUrY9LOmd",
        "colab": {}
      },
      "source": [
        "count_words = article_vocabulary_size\n",
        "embedding_matrix = np.zeros((count_words, 300))\n",
        "for word, i in combined_vocabulary.items():\n",
        "    if i >= article_vocabulary_size:\n",
        "        continue\n",
        "\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZJ9afS37LOmf",
        "colab": {}
      },
      "source": [
        "embedding_layer_combined = Embedding(count_words, 300, embeddings_initializer=Constant(embedding_matrix),\n",
        "                                     input_length=max_length_article, trainable=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVeWZf9p8UGn",
        "colab_type": "text"
      },
      "source": [
        "#### Prepare Embedding Matrix – Headline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "esCE741O8W0B",
        "colab": {}
      },
      "source": [
        "count_words = headline_vocabulary_size\n",
        "embedding_matrix = np.zeros((count_words, 300))\n",
        "for word, i in headline_vocabulary_size.items():\n",
        "    if i >= max_:\n",
        "        continue\n",
        "\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mJu6BYGK8W0D",
        "colab": {}
      },
      "source": [
        "embedding_layer_combined = Embedding(count_words, 300, embeddings_initializer=Constant(embedding_matrix),\n",
        "                                     input_length=max_length_headline, trainable=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfEe-C90RwEc",
        "colab_type": "text"
      },
      "source": [
        "### GPT-2 Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5jkmUdJaf5v_"
      },
      "source": [
        "#### Define Values for Embedding Logic / Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DzvHkjsgf5wB",
        "colab": {}
      },
      "source": [
        "embedding_dimension = 768"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UPLq7Lif67y",
        "colab_type": "text"
      },
      "source": [
        "#### Read GPT-2 Model / Tokeniser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0rQKf2OR2tt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "tokeniser = GPT2Tokenizer.from_pretrained('gpt2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Du7tmOmVd6W8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_embeddings = model.transformer.wte.weight\n",
        "position_embeddings = model.transformer.wpe.weight"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BHT6Z2YOf0EU"
      },
      "source": [
        "#### Prepare Embedding Matrix – Article"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6skRyGIvf0EX",
        "colab": {}
      },
      "source": [
        "count_words = article_vocabulary_size\n",
        "embedding_matrix = np.zeros((count_words, embedding_dimension))\n",
        "for word, i in article_vocabulary.items():\n",
        "    if i >= article_vocabulary_size:\n",
        "        continue\n",
        "\n",
        "    text_index = tokeniser.encode(word, add_prefix_space=True)\n",
        "    embedding_vector_tensor = model.transformer.wte.weight[text_index, :]\n",
        "    embedding_vector_np = embedding_vector_tensor.detach().numpy()[0]\n",
        "    if embedding_vector_np is not None:\n",
        "        embedding_matrix[i] = embedding_vector_np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bf7AbSitf0Ea",
        "colab": {}
      },
      "source": [
        "embedding_layer_article = Embedding(count_words, embedding_dimension,\n",
        "                                    embeddings_initializer=Constant(embedding_matrix),\n",
        "                                    input_length=max_length_article,\n",
        "                                    trainable=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5gLqHk3Mf0Ec"
      },
      "source": [
        "#### Prepare Embedding Matrix – Headline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hY5QbAV3f0Ee",
        "colab": {}
      },
      "source": [
        "count_words = headline_vocabulary_size\n",
        "embedding_matrix = np.zeros((count_words, embedding_dimension))\n",
        "for word, i in headline_vocabulary.items():\n",
        "    if i >= headline_vocabulary_size:\n",
        "        continue\n",
        "\n",
        "    text_index = tokeniser.encode(word, add_prefix_space=True)\n",
        "    embedding_vector_tensor = model.transformer.wte.weight[text_index, :]\n",
        "    embedding_vector_np = embedding_vector_tensor.detach().numpy()[0]\n",
        "    if embedding_vector_np is not None:\n",
        "        embedding_matrix[i] = embedding_vector_np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VouaUExVf0Ei",
        "colab": {}
      },
      "source": [
        "embedding_layer_headline = Embedding(count_words, embedding_dimension,\n",
        "                                     embeddings_initializer=Constant(embedding_matrix),\n",
        "                                     input_length=max_length_headline,\n",
        "                                     trainable=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kj5LxKYnCFX3",
        "colab_type": "text"
      },
      "source": [
        "## Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xag3OJ99izY",
        "colab_type": "text"
      },
      "source": [
        "### Define Network (Full Articles)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAHgV8GpN_LY",
        "colab_type": "code",
        "outputId": "840b6eda-6336-471e-d8cf-a33167dd0abb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        }
      },
      "source": [
        "### Constructor for baseline enc. dec. network.\n",
        "\n",
        "latent_dimension = 256\n",
        "encoder_input = Input(shape=(max_length_article, ))\n",
        "decoder_input = Input(shape=(None, ))\n",
        "\n",
        "# Encoder\n",
        "encoder_embedding = embedding_layer_article(encoder_input) \n",
        "\n",
        "# GRU 1\n",
        "encoder_gru_01 = Bidirectional(CuDNNGRU(latent_dimension, return_sequences=True, return_state=True))\n",
        "encoder_output_01, encoder_forward_state_01, encoder_backward_state_01 = encoder_gru_01(encoder_embedding)\n",
        "encoder_output_dropout_01 = Dropout(0.3)(encoder_output_01)\n",
        "\n",
        "# GRU 2\n",
        "encoder_gru_02 = Bidirectional(CuDNNGRU(latent_dimension, return_sequences=True, return_state=True))\n",
        "encoder_output, encoder_forward_state, encoder_backward_state = encoder_gru_02(encoder_output_dropout_01)\n",
        "encoder_state = Concatenate()([encoder_forward_state, encoder_backward_state])\n",
        "\n",
        "# Decoder.\n",
        "decoder_embedding = embedding_layer_headline(decoder_input)\n",
        "\n",
        "# GRU using encoder_states as initial state\n",
        "decoder_gru = CuDNNGRU(latent_dimension*2, return_sequences=True, return_state=True)\n",
        "decoder_output, decoder_state = decoder_gru(decoder_embedding, initial_state=[encoder_state])\n",
        "\n",
        "# Attention Layer\n",
        "attention_layer = AttentionLayer() \n",
        "attention_out, attention_states = attention_layer([encoder_output, decoder_output])\n",
        "  \n",
        "# Concat attention output and decoder GRU output \n",
        "decoder_concatenate = Concatenate(axis=-1)([decoder_output, attention_out])\n",
        "\n",
        "# Dense layer\n",
        "decoder_dense = TimeDistributed(Dense(headline_vocabulary_size, activation='softmax')) #hierarchical\n",
        "decoder_dense_output = decoder_dense(decoder_concatenate)\n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_input, decoder_input], decoder_dense_output)\n",
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_12\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_15 (InputLayer)           [(None, 550)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 550, 768)     38941440    input_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_6 (Bidirectional) [(None, 550, 512), ( 1575936     embedding[3][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 550, 512)     0           bidirectional_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "input_16 (InputLayer)           [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_7 (Bidirectional) [(None, 550, 512), ( 1182720     dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, None, 768)    17270016    input_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 512)          0           bidirectional_7[0][1]            \n",
            "                                                                 bidirectional_7[0][2]            \n",
            "__________________________________________________________________________________________________\n",
            "cu_dnngru_11 (CuDNNGRU)         [(None, None, 512),  1969152     embedding_2[7][0]                \n",
            "                                                                 concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "attention_layer_7 (AttentionLay ((None, None, 512),  524800      bidirectional_7[0][0]            \n",
            "                                                                 cu_dnngru_11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, None, 1024)   0           cu_dnngru_11[0][0]               \n",
            "                                                                 attention_layer_7[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_3 (TimeDistrib (None, None, 22487)  23049175    concatenate_11[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 84,513,239\n",
            "Trainable params: 28,301,783\n",
            "Non-trainable params: 56,211,456\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zRe_KTnpPWD",
        "colab_type": "text"
      },
      "source": [
        "### Compile & Train Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUGCQ_uPJ9QF",
        "colab_type": "code",
        "outputId": "ec570ce2-ab1a-42c9-f3d9-d81219c7e6da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "os.chdir('/gdrive/My Drive/colab_notebooks/information_systems/data/model_checkpoints')\n",
        "callbacks = [ModelCheckpoint(filepath='encoder_decoder_01_{epoch:02d}-{val_loss:.2f}.hdf5'), \n",
        "             EarlyStopping(monitor='val_loss', patience=1, verbose=1, min_delta=1e-4, restore_best_weights=True)]\n",
        "\n",
        "model_history = model.fit([train_sequences_article, train_sequences_headline[:, :-1]], \n",
        "                          train_sequences_headline.reshape(train_sequences_headline.shape[0], train_sequences_headline.shape[1], 1)[:, 1:], \n",
        "                          epochs=50, verbose=1, batch_size=150, callbacks=callbacks, validation_split=0.20, shuffle=True)\n",
        "\n",
        "model.save('encoder_decoder_17.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 200310 samples, validate on 50078 samples\n",
            "Epoch 1/50\n",
            "200310/200310 [==============================] - 1561s 8ms/sample - loss: 3.1604 - val_loss: 2.9862\n",
            "Epoch 2/50\n",
            "200310/200310 [==============================] - 1563s 8ms/sample - loss: 2.8539 - val_loss: 2.8649\n",
            "Epoch 3/50\n",
            "200310/200310 [==============================] - 1558s 8ms/sample - loss: 2.7071 - val_loss: 2.7974\n",
            "Epoch 4/50\n",
            "200310/200310 [==============================] - 1572s 8ms/sample - loss: 2.5992 - val_loss: 2.7666\n",
            "Epoch 5/50\n",
            "200310/200310 [==============================] - 1564s 8ms/sample - loss: 2.5102 - val_loss: 2.7659\n",
            "Epoch 6/50\n",
            "200250/200310 [============================>.] - ETA: 0s - loss: 2.4327Restoring model weights from the end of the best epoch.\n",
            "200310/200310 [==============================] - 1565s 8ms/sample - loss: 2.4328 - val_loss: 2.7828\n",
            "Epoch 00006: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKBa1wAHjSJ8",
        "colab_type": "text"
      },
      "source": [
        "### Construct Word Index to Word Dict."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vHXrzdPjSiL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reverse_target_word_index = headline_tokeniser.index_word\n",
        "reverse_source_word_index = article_tokeniser.index_word\n",
        "target_word_index = headline_tokeniser.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duFWMa2rpS70",
        "colab_type": "text"
      },
      "source": [
        "### Define Inference Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lAhN9TjpSyv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encoder Inference Model\n",
        "encoder_model_inference = Model(encoder_input, [encoder_output, encoder_state])\n",
        "\n",
        "# Decoder Inference\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state = Input(shape=(latent_dimension*2, ))\n",
        "decoder_intermittent_state_input = Input(shape=(max_length_article, latent_dimension*2))\n",
        "\n",
        "# Get Embeddings of Decoder Sequence\n",
        "decoder_embedding_inference = embedding_layer_headline(decoder_input)\n",
        "\n",
        "# Predict Next Word in Sequence, Set Initial State to State from Previous Time Step\n",
        "decoder_output_inference, decoder_state_inference = decoder_gru(decoder_embedding_inference, initial_state=[decoder_state])\n",
        "\n",
        "# Attention Inference\n",
        "attention_layer = AttentionLayer()\n",
        "attention_out_inference, attention_state_inference = attention_layer([decoder_intermittent_state_input, decoder_output_inference])\n",
        "decoder_inference_concat = Concatenate(axis=-1)([decoder_output_inference, attention_out_inference])\n",
        "\n",
        "# Dense Softmax Layer to Generate Prob. Dist. Over Target Vocabulary\n",
        "decoder_output_inference = decoder_dense(decoder_inference_concat)\n",
        "\n",
        "# Final Decoder Model\n",
        "decoder_model_inference = Model([decoder_input, decoder_intermittent_state_input, decoder_state], \n",
        "                                [decoder_output_inference, decoder_state_inference])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_DvHO0gk6k2",
        "colab_type": "text"
      },
      "source": [
        "### Define Sequence Decoder Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9jXPJjVk6aS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_sequence):\n",
        "  \"\"\"Text generation function via encoder / decoder network.\"\"\"\n",
        "\n",
        "  # Encode Input as State Vectors.\n",
        "  encoder_output, encoder_state = encoder_model_inference.predict(input_sequence)\n",
        "\n",
        "  # Generate Empty Target Sequence of Length 1.\n",
        "  target_sequence = np.zeros((1, 1))\n",
        "\n",
        "  # Choose 'start' as the first word of the target sequence\n",
        "  target_sequence[0, 0] = target_word_index['tokenstart']\n",
        "\n",
        "  decoded_sentence = ''\n",
        "  break_condition = False\n",
        "  while not break_condition:\n",
        "      token_output, decoder_state = decoder_model_inference.predict([target_sequence, encoder_output, encoder_state])\n",
        "\n",
        "      # Sample Token\n",
        "      sampled_token_index = np.argmax(token_output[0, -1, :])\n",
        "\n",
        "      if not sampled_token_index == 0:\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "\n",
        "        if not sampled_token == 'tokenend':\n",
        "            decoded_sentence += ' ' + sampled_token\n",
        "\n",
        "        # Break Condition: Encounter Max Length / Find Stop Token.\n",
        "        if sampled_token == 'tokenend' or len(decoded_sentence.split()) >= (max_length_headline - 1):\n",
        "            break_condition = True\n",
        "\n",
        "        # Update Target Sequence (length 1).\n",
        "        target_sequence = np.zeros((1, 1))\n",
        "        target_sequence[0, 0] = sampled_token_index\n",
        "\n",
        "      else:\n",
        "        print('BROKEN')\n",
        "        break_condition = True\n",
        "\n",
        "      # Update internal states\n",
        "      encoder_state = decoder_state\n",
        "\n",
        "  return decoded_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6M3IGFVpG7K",
        "colab_type": "text"
      },
      "source": [
        "#### Integer Sequence to Headline Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6npZ8dqbpGtV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sequence_to_headline(input_sequence):\n",
        "  new_string = ''\n",
        "  for item in input_sequence:\n",
        "    if (not item == 0 and not item == target_word_index['tokenstart']) and not item == target_word_index['tokenend']:\n",
        "      new_string = new_string + reverse_target_word_index[item] + ' '\n",
        "\n",
        "  return new_string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9248dNE6pJCD",
        "colab_type": "text"
      },
      "source": [
        "#### Integer Sequence to Article Text\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e6m6u1IpI3I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sequence_to_article(input_sequence):\n",
        "  new_string = ''\n",
        "  for item in input_sequence:\n",
        "    if not item == 0:\n",
        "      new_string = new_string + reverse_source_word_index[item] + ' '\n",
        "  \n",
        "  return new_string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SvGck_Rp3ZZ",
        "colab_type": "text"
      },
      "source": [
        "#### Generate Test Summaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ols3e3HXhMzG",
        "colab_type": "code",
        "outputId": "66356c4b-7cfa-49e1-f45d-62aadc97e002",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 925
        }
      },
      "source": [
        "for i in range(len(test_sequences_article))[:10]:\n",
        "  print('Article:', sequence_to_article(test_sequences_article[i]))\n",
        "  print('Original Headline:', sequence_to_headline(test_sequences_headline[i]))\n",
        "  print('Predicted Headline:', decode_sequence(test_sequences_article[i].reshape(1, max_length_article)))\n",
        "  print('\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Article: savvy consumer knows price gasoline drops service station convenience store competitors rush match beat price win customers goes products services days healthy competition drain flying public south east coast proposed billion hostile takeover delta air lines airways reality airline analysts beginning assert merger create monopoly conservatives believe healthy consumers new delta result airways delta air lines merger nations largest air carrier consider comments michael boyd president boyd group inc told wall street journal concentration flights destroy competition deep south stuart aviation consulting told reuters carriers overlap typically reduction service room upward pressure pricing loss competition critical monopolies good flying public federal government rejected bid airways merge united primarily overlapping flights airlines recently rejected merger northwest american airlines reason justice department duty sure merger harm public unfortunately consumers west recent merger america west airways gone smoothly airlines combine operations resolve labor issues overlapping routes delta like major airline gotten bad rap sept able operate profit successfully lowered expenses tough negotiations pilots union added profitable routes overseas restructured domestic service projected emerge bankruptcy year good states largest employers especially light collapse eastern airlines years ago recent corporate losses bellsouth georgia pacific deltas reputation far exceeds airways especially customer satisfaction time performance key measures airline industry recent expansion hartsfield jackson international airport olympics attributed deltas success members creditors committee care city cost merger consumer public officials washington georgia obligation step consumer choice eliminated upward pressure prices past state stepped plate bring jobs georgia incentives companies newell rubbermaid recent kia plant west georgia retain large employer delta expect general assembly commence hearings shortly explore incentives sure delta stands independent carrier keeps headquarters atlanta economy region state depends state rep mark burkhalter republican alpharetta graphic photo mark burkhalter imagedata \n",
            "Original Headline: an independent vibrant delta is worth state support \n",
            "Predicted Headline:  q and a business\n",
            "\n",
            "\n",
            "Article: ohio years ago month september presidency long ignored discredited president william mckinley traveled hometown predecessor mentor rutherford b hayes gentle moment young mckinley presidency gentle moment soon crowded hour american history sinking battleship uss maine months future war spain seven months away vital debate imperialism looming mckinley came september visit grave hayes embattled president embattled nation spend time old fellow soldiers ohio volunteer infantry regiment president referred major dual roles commander chief country merely battlefield courier old regiment fought bravely civil war antietam shenandoah valley addressed fellow veterans remarks rooted time relevant comrades memories war sweeter service war good deal safer fight battles today fight glorious memories rendered service service rendered freedoms cause country forever saved passage followed simple greeting men assembled president spoke lightly gravely burden cost war felt burden cost young man experienced hostilities battle defeat firsthand experience president sending men combat cuba philippines reference sentence passage freedoms cause recurrent theme american presidency american history spoken woodrow wilson world war franklin roosevelt harry truman world war ii john kennedy lyndon johnson richard nixon vietnam george hw bush george w bush iraq mckinley set nation wartime course win freedom cubans oppressed spanish old flag shot men fly pick lift aloft duty anybody union soldiers duty honor glory reunited country mckinley remarks pointing flag came fremont honor passage won cheers veterans regiment assembled import sentence comes words duty reunited following terrible american wars pitted northern duty southern duty testing abraham lincoln gettysburg century earlier country long endure notion reuniting country vital task today face divided nation prudent recall divided revolutionary tory republican federalist south north black white greatest generation baby boomers divisions today conservative liberal mainstream media insurgents right significant compare divisions preceded reason national leaders dedicate finding common cause common ground difficult budget race national security questions unresolved need difficult days come price sacrifice today instead having sectional divisions beneath flag obliterated men fought flag men opposed battlefields south forever united faith friendship defense mckinley speaking end century decades end war living memory republicans engaged practice called waving bloody shirt attempt discredit democrats reminding voters ties rebellious south president saying sectional divisions gone nation united man look great american audience today feel countrys institutions safe flag hand child patriotism mans heart tensions civil war fast receding learn century reaffirm sectional racial tensions produced war long painful legacy played debate confederate statues mckinley want linger tensions speech celebratory day included cannon salutes band music bonfire events robert w merry sparkling new mckinley biography published november described reflecting sturdy patriotism day lessons september americans september clear reflected new biography mckinley mr merry wrote knew unity social harmony required good times sense american prosperity widely shared notion applies time political divisions reflection cultural economic divisions time wealth education cultural perception gaps today possible successor president donald trump look fourth july celebrations flag hand child patriotism americans heart look great american audience believe countrys institutions safe making greatest task republicans democrats congress months come notes david shribman executive editor post gazette dshribman post gazettecom graphic photo white house william lessons apply years later classification language english publication type newspaper subject war conflict history world war ii world war civil war person john f kennedy george h w bush george w bush richard nixon geographic ohio usa united states philippines iraq cuba viet nam \n",
            "Original Headline: president devotion to duty the president who knew the civil war firsthand speaks to us today \n",
            "Predicted Headline:  the great american great depression\n",
            "\n",
            "\n",
            "Article: hyundai hybrid blue real economy finally come masses price tested options test vehicle marketers pitch hybrid compromise conventional wisdom car driver likes quicker cheaper better looking prius equally efficient hardly thrilling needs little refinement reality beating toyota game bare bones like stripped test car auto writer sense car underneath better way try hyundais new hybrid hatchback cloth seats basic infotainment simple heater controls mr drivers seat days yore new offers little years hybrids cylinder engine mated electric motor captures brake pedal energy recharge battery help conserve fuel economy worry plugging test model cord planned shape things borrows wind cheating profile prius split rear window interfering rear visibility reducing drag saving fuel little hyundai shares underpinnings kia niro offers lesson weight shape niro weighs pounds shaped like soul weighs pounds shaped like prius write numbers later reference quiz shifty copying guys offers real honest goodness speed shiftable automatic transmission feeling old timers like controlling gears power engine improve performance economy liking speed combined horsepower liter engine motor rocket little car runs rings prius fun switch gearshift shiftable sport light comes nice car gets little peppy test couple pull situations passing spots found run medium dogs big ones car driver reports time seconds sneeze fuel economy let let cooler heads prevail conserve fuel despite harsh tests observed mpg highway heavy round driving high speed conditions ideal hybrids regenerative braking kia niro averaged mpg similar mr drivers seat testing road country roads exactly fun car handled aplomb batteries add cornering pulling weight car wheels drivers seat bare bones cloth interior sported seats felt like mrs passenger seats old kia soul base comfortable fabric long cooled jets plenty support long drives uncomfortable manual adjustments worked fine friends stuff rear seat roomy foot inch passenger sit driver size reasonable comfort cargo bay holds cubic feet rear seats astounding number small car outside wince look unlike lightning lighted prius kind cute play tunes bare bones stereo featured apple carplay hyundai navigation system end mr drivers seat bonded plug capability near sound hear driving road prius owners gasping notes scott sturgis freelance auto writer reached atgraphic photo hyundai classification language english publication type newspaper subject writers company hyundai motor co ticker lse industry writers \n",
            "Original Headline: hyundai hybrid blue beats toyota at its own game \n",
            "Predicted Headline:  infiniti is a good thing\n",
            "\n",
            "\n",
            "Article: america remembers rev martin luther king jrs legacy today thoughts hopes dreams education program king preacher scholar phd dangerous build society large segment people feel stake feel lose people stake protect society stake unconsciously want destroy happen largely poor uneducated nations witness ongoing civil turmoil developing countries swelling ranks juvenile justice adult prison systems functionally illiterate offenders feel stake productive law abiding society reduce americas persistent racial economic education gaps king proud recently announced collaboration minneapolis community technical college st paul college metropolitan state university local foundations power program aggressive outreach elementary secondary students prepare college help provide years free tuition academic support institutions st paul minneapolis high school graduates foundations expect raise million cover costs federal pell grants student participants lower income students color similarly week florida gov jeb bush announced diversity initiative substantially increase minority enrollment floridas universities governor wants increase need based financial aid scholarships combined million year good portion helped needy students color examples educational programs king promoted directly address major cause americas poverty dramatic differences education turn lead huge income disparities efforts models communities states globally competitive technological information age education high school longer luxury necessity chance economically stable productive adult life contributing stakeholders society king fodder destructive behavior king fought racism discrimination housing employment education equally passionate economic discrimination civil rights icon wealthy nation like united states poverty stand teenager good education words function education teach think intensively think critically integrity plus character goal education audacity believe people meals day bodies education culture minds dignity equality freedom spirits martin luther king jr \n",
            "Original Headline: kings dreams for higher learning the civil rights icon worked for equality in education \n",
            "Predicted Headline:  we cannot afford to be a better\n",
            "\n",
            "\n",
            "Article: james grant cluttered office wall street overlooks trinity church warning financial disaster form nearly years years ago example beleaguered morgan stanley trumpeting percent jump profits grant wrote pessimistic analysis titled cliff morgan stanley financial industry gone cliff bears street editor author gloomy grants interest rate observer victory lap saying told reached phone yesterday grant tried gloat costliest words finance different time told brings wrath gods gods sent plenty wrath grant admits surprised ferocity violence events shaken financial world past weeks bearish grant looking nearly calamity read grants socialization credit risk long run trend yield weeks outright nationalization financial system sentence write things happened dramatic violent way kenneth rogoff economics professor harvard university chief economist international monetary fund reason point foresight conference year ago predicted major bank fail july doubted treasury secretary henry paulson jrs assertion fannie mae freddie mac remain form toast rogoff month ago analysts thought worst financial instability passed rescue bear stearns rogoff told group failures way financial institutions reporting awe inspiring profits annual bonus payments tens hundreds millions dollars outside saying possible manufacture money like goldman bonuses financial services economy rogoff answer taking bigger risks profiting sort wisdom easy thing charles co portfolio manager grizzly short fund leuthold weeden capital management minneapolis says fund betting largely decline financial stocks past years recently betting consumer discretionary shares equally weighted positions cautions fund smallest leuthold weeden funds search stocks rise philosophy markets markets percent time time ugly times grizzly fund look like beautiful creature percent jan close business wednesday percent thursday meant buy hold fund says past years returns slightly negative knows tomorrow comes tomorrow long term pessimists pessimistic think central banks going wear goat horns grant saying fed central banks lose credibility wade deeper managing banks insurance companies referring federal reserve chairman alan greenspan current chairman ben bernanke grant old days maestro ran fed people attributed qualities guy came mere mortal given benefit doubt turns prophet rogoff says think government ultimately pressed radical measures predicts expansion federal deposit insurance new institution similar resolution trust corporation bailed savings loan institutions decades ago need treasury fed shell trillion restore stability prescient economic prognosticators nouriel roubini economic professor new york university founder monitor economic consulting commentary firm past weeks roubini lashing bush administration blog calls president treasury secretary fed chairman comrades bush paulson bernanke brands laissez faire voodoo economics zealots says united states turned united socialist state republic america bringing socialism rich connected wall street making sure profits privatized losses socialized grant bit humility reason march recommended people buy american international group insurance giant federal government seized control prevent cash short firm causing greater market turmoil points reversed opinion point notes stock digits attached federal takeover aig sells share best words wrote year wrong aig grant \n",
            "Original Headline: over the cliff saying i told you so \n",
            "Predicted Headline:  the economy is not the answer to the problem\n",
            "\n",
            "\n",
            "Article: beamed far outer space analyzed tweeted death seconds delivery state union address president obama fell admiring disgusted ears tuesday night feel lost ages real time nation practically checking comment retweeted think favorite rt evening trying come neat way saying john boehner looks like apricot couldnt like longer watch important live televised addresses wit wisdom virtual friends live iphone funny stopping spot fact checking long appropriately acknowledge presidents deserve vote refrain grieving survivors victims gun violence snark somber fast exhausting distracting president successors struggle decades obeying formal theatrics state union address speaking global audience wired americans receptive message good audience president confidently delivered speech filled steady stream second term proposals hopeful visions address twice long total words rousing inauguration address weeks ago lines emerged middle class sort jobs future act raising minimum wage hour decade grinding war brave men women uniform coming home president litany heard years grueling recession businesses created million new jobs buy american cars years foreign oil housing market healing stock market rebounding consumers patients homeowners enjoy stronger protections cleared away rubble crisis renewed confidence state union stronger earlier evening cable networks able pull away riveting story unfolding mountains miles east los angeles law enforcement officers possibly cornered christopher ex police officer turned slaying suspect americans look away cabin woods ablaze poor chris matthews msnbc devote hour leading state union address easily second biggest night punditry year breaking news irritated tell took like man fox news bill oreilly laura ingraham minutes segue california standoff dripping disgust obama stage state union thing oreilly asked ingraham sadly quasi reality heres drives crazy oreilly watch joe biden jump scream ah ya ya ya like golden globes oscars equivalent washington like white house correspondents dinner state union morphed event later making outdated crack viral video david eating hamburgers floor miserable forget best times watch fox miserable rove ohio results lot suffering left intriguing alternative watching dumb ol television view state union prism white houses streaming video network possible youtube channel state union henceforth known split screened adorned dazzling array maps percentages dollar amounts pie charts bar graphs attributed tiny type rendered agreed san text color schemes modern day learned americans spend billion hours year working tax returns standoff debt ceiling costs added interest years energy related emissions way immigrants represent percent nations engineers true true ones eyes ears easily crammed tv twitter value makes known hears sees things way forget notice ill equipped notice right away picked fashion policed easter egg symmetry neckties worn president vice president speaker house curated twitter feed alert clunker middle obamas speech know economy stronger wives mothers daughters live lives free discrimination workplace free fear domestic violence note wives mothers daughters ears sounds like speech delivered time pundits got television half hour later probably remember mention sen marco rubio fla got dubious honor delivering republican rebuttal regardless party affiliation political ambitions person takes job deserves coming deserves measure sympathy pretty winds looking like frightened robot amid pleas cutting government spending preserving second amendment dry mouthed senator reached reaching panic button gun chart turned bottle water awkwardly frame camera gulp gulp sputter oh howled comforts virtual judgment washpostcom \n",
            "Original Headline: reaching the peanut gallery \n",
            "Predicted Headline:  the state of the union\n",
            "\n",
            "\n",
            "Article: march mark bradley chopper inches shorter tommy hanson lacks pants relocated minor league team open major league market time economic uncertainty team bruce baldwin asked spend days nights praying ballyhooed pitcher tommy hanson winds guy atlanta braves man roster baldwin general manager brand new gwinnett braves read great talent great young man hope able serve braves way best career ok boilerplate baldwin like gwinnett absolutely g braves start inaugural season road dates christen new stadium april baldwin pitch pm gates open having heralded braves pitching prospect steve avery hill friday sweetest reality possible baldwin spent seasons gm richmond braves knows drill minor leagues serve pleasure parent club organization wants class aaa affiliate rolling start tommy hanson needed speaking monday florida braves gm frank wren know early got weeks thrown ball april destination year old hanson figures hinge march performance somewhat older tommy braves signed tom glavine major league debut came days hansons birthday fifth starter want hanson bigs going regular turn braves starter scheduled work april tommy hanson wearing pants shown rich addicks ajc betting bet hanson begin season minors glavine coming surgery threw innings game monday guarantee post surgical year olds gwinnett braves wind players big team sends hansons comes baldwin roster moving target moving target baldwin ticks names big prospects came richmond chipper jones lopez mike kelly tony vinny nature minor leagues big prospect stick long weve got business models baldwin inside white lines outside white lines g braves work outside finishing stadium baldwin county amazing job nice looking place looks little different near mall georgia printed schedules selling tickets got mascot foot groundhog uncertain named chopper going field team play season tommy hanson toes slab gwinnett county dont think blase baldwin im excited passionate organization opportunity bring baseball community control certain players wind dont tommy hanson lawrenceville dandy borrow word famous gwinnett water tower great http blogsajccom mark bradley blog gwinnetts hopes hanson tempered reality \n",
            "Original Headline: gwinnetts hopes for hanson are tempered by reality \n",
            "Predicted Headline:  q and a new york\n",
            "\n",
            "\n",
            "Article: economy looking good deal college admissions schools city university new york tuition costs year way coming spring semester university announced new freshman enter college spring semester admitted spring year increase percent year transfers way little students transfer spring semester year compared year increase percent come schools outside cuny system school transfers came outside cuny system spring largest increases transfer admissions baruch hunter york la guardia bronx borough manhattan community colleges students apply getting better prepared students averages greater increased percent compared year dr robert senior university dean executive office enrollment statement school spokesman hailed increase evidence public sees cuny prestigious degree price beat combination valued degree fact environment economy unforgiving school spokesman michael arena people looking different new options options cuny school says applied deadline fall class honors college increase applied year influx new freshman cuny adjustments staff class sizes spring semester colleges hire adjuncts timers meet midyear enrollment increases class size increase colleges largest increases arena overall clear students choosing cuny value quality high standards affordability unforgiving economy higher education admissions cuny spring spring pct change freshmen cuny schools transfers cuny transfers outside cuny \n",
            "Original Headline: on an enroll roll cuny admissions jump as economy slumps \n",
            "Predicted Headline:  online your means to be a better than ever\n",
            "\n",
            "\n",
            "Article: best known lawyers week hold smashed doors windows tossed computers ransacked files beat standing way iron tipped batons tear gas hear cries lawyers counselor courtyard raid clear message pakistans president gen pervez musharraf cross like lawyers country failing heed controversy gripped pakistan poses challenge musharrafs leadership nations executive judiciary clashing presidents decision nearly weeks ago suspend supreme court chief justice lawyers black suits staged daily protests presidents political opponents joined police responded raids including nations popular television station major protest expected wednesday capital islamabad organizers calling nationwide strike lawyers musharraf critics protests far decision suspend judge larger question pakistan governed rule law man rule people starting deeply resent idea knows right pakistan rest million bloody idiots haider news editor friday times newspaper musharraf ally came power nearly years ago bloodless coup defended suspension saying allegations judge obligated refer special council rule matter far exact allegations public behavior police president tried distance alleged conspiracy government embarrass musharraf denied accusations trying manufacture emergency postpone elections fall forward course elections year year tenure assemblies completed firmly resolved interview monday geo television private pakistani network raided police days earlier critics unconvinced suspension effort autocratic president snuff fledgling democratic institutions challenge authority attack judiciary institution tomorrow institutions victims attack ahsan president lahore high court bar association dictator stopped anarchy civil war pakistani legal experts musharraf rights referring allegations chief justice iftikhar mohammad chaudhry special council review erred suspending chaudhry council ruled allegations tuesday pakistans deputy attorneys general resigned saying crisis difficult perform duties reuters news agency reported chaudhry appointed musharraf won praise legal circles willingness stand government late year instance pressed information individuals allegedly disappeared hands nations intelligence services elections pose major test musharraf later year chaudhry expected rule issues complicate presidents bid term open questions musharraf face vote current parliament endorse term head state new parliament view favorably current parliament came power elections marked irregularities doubt musharraf resign post head army critical job pakistan power comes uniform comes constitution ali shah leading opposition figure political opponents quick lawyers dispute chaudhry musharraf came power opposition badly fractured vigorous economic growth tenure plus failure past democratic governments difficult opponents mount strong challenge recent weeks right left wing groups stood shoulder shoulder demonstrations received support abroad state department spokesman sean mccormack defended president saying tuesday president musharraf commitment change pakistan think positive thing western diplomat musharraf blunder time recover badly away couple days diplomat spoke condition anonymity authorized speak publicly issue telling start seeing average citizens lawyers party members coming streets protests going major urban centers general publics failure join demonstrations far result nature controversy hinges complex constitutional questions country illiteracy rates percent lahore long intellectual cultural capital country thousands lawyers taken citys frenetic streets protest saturday preparing lead demonstration century old court buildings police preemptively assaulted tear gas rocks baton charges days later admitted throwing rocks doubt police initiated fracas armed weapons words hand wrapped bandages struck baton defending father earlier protest week father lawyer needed stitches close wound forehead hit lawyers injured saturday lahore offices ransacked citys police chief declined comment boisterous meeting monday hundreds lawyers listened speech speech condemning president responded chanting musharraf departing lawyers told prepare protest wednesday lawyers peaceful speaker afraid bullets graphic image km associated press lawyers lahore rally ouster pakistans chief justice ahead protest today islamabad organizers called nationwide strike \n",
            "Original Headline: lawyers press musharraf with protests clash over judge grows into challenge of pakistani leaders rule \n",
            "Predicted Headline:  in china a president is a tough place to be president\n",
            "\n",
            "\n",
            "Article: eric levin helped record store day annual event support independent record stores worldwide shutter music store criminal records nov making bad business decisions nations recession weve underwater economy distressed founder owner levin tuesday weve rescue mission years paying independent record stores nationwide saying compete amazon itunes big box retailers sell new releases deep discounts criminal closes leave metro atlanta half dozen independent stores sell new cds vinyl records levin rattled nearly independent music stores atlanta decatur shuttered recent years unfortunate digital music people stores sean bourne manager wax n facts started little points years ago store sells new cds vinyl records music related items bourne cd sales dwindled percent line far fine bourne far criminal goes solid fan base business agile moods music criminals neighbor street found business plan works addition music sells items soy wax candles soaps oils dvds t shirts far ok think kind helps specialized kind store owner darryl harris niche market think based kind keeps going criminals growth downfall levin square foot space tripled expenses hosting live music times week free costly recession legal illegal music downloading levin called miserable holiday season retail sales dug hole deeper day freeze januarys ice storm cost store gave anniversary drowning august pull plug levin federal state aid struggling small business like bank credit union turned going debt wasnt going work debt load problem got point levin levin owns aurora coffee moreland avenue unclear considering liquidation sale combining store aurora local musicians artists want sell cds t shirts art raise money business running levin landlord discounted rent past patient retail business cds vinyl records comic books magazines graphic novels par levin store typically buys cds sells average margin board percent levin percent margin break record store jobs known high wages levin offers member staff health insurance proud levin rarely criminal work outside store helped international brand president alliance independent media stores co founder record store day fourth year april independent stores participated worldwide showcasing bands releasing new music special criminal records opened euclid avenue java lords coffee shop stages variety playhouse levin started selling comics immediately local comic shop closed subscribers come store weekly pick comics store orders store settled square foot space aurora coffee offbeat vintage retail shop daughter levin bought struggling aurora years later criminal returned euclid avenue mark malek visited criminal tuesday hearing store close customer uniquely human having physical location physical record selection look malek fun wait things mail \n",
            "Original Headline: criminal records plans to close in november \n",
            "Predicted Headline:  music store sales are down\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcKkrVkTwR5a",
        "colab_type": "text"
      },
      "source": [
        "### Assign Generated Summaries to Data Frame & Save"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2RRLjV4wRep",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPU_train['Headline_Gen'] = [decode_sequence(sequence.reshape(1, max_length_article)) for sequence in train_sequences_article]\n",
        "EPU_test['Headline_Gen'] = [decode_sequence(sequence.reshape(1, max_length_article)) for sequence in test_sequences_article]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xC7amrd9eI8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPU_train.to_csv('EPU complete_train_full.csv')\n",
        "EPU_test.to_csv('EPU complete_train_full.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cKQklyh69IR",
        "colab_type": "text"
      },
      "source": [
        "## Fix Data Output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwXOvKbwd6S6",
        "colab_type": "text"
      },
      "source": [
        "### Load Dataframe Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVKkgA--d6Cp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPU_train_full = pd.read_csv('EPU_complete_train_full.csv')\n",
        "EPU_test_full = pd.read_csv('EPU_complete_test_full.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msVU2m7G0aS9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df = pd.DataFrame()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gt-Ce-mE1EJx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences = [sequence_to_article(test_sequences_article[i]) for i in range(len(test_sequences_article))]\n",
        "headlines = [sequence_to_headline(test_sequences_headline[i]) for i in range(len(test_sequences_headline))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pB2ae20C0c1a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df['Article'] = sequences\n",
        "test_df['Headline'] = headlines\n",
        "test_df['Headline_Gen'] = EPU_test_full['Headline_Gen']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fqw5EUjM3B1t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences = [sequence_to_article(train_sequences_article[i]) for i in range(len(train_sequences_article))]\n",
        "headlines = [sequence_to_headline(train_sequences_headline[i]) for i in range(len(train_sequences_headline))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IcrQlQs5WT6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.DataFrame()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfjUZ07W3A-v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df['Article'] = sequences\n",
        "train_df['Headline'] = headlines\n",
        "train_df['Headline_Gen'] = EPU_train_full['Headline_Gen']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pqPflPZ27Ak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPU_test_full_clean = test_df\n",
        "EPU_train_full_clean = train_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBxvw3xq5mtt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPU_test_full_clean.to_csv('EPU_complete_train_full_FIXED.csv')\n",
        "EPU_train_full_clean.to_csv('EPU_complete_test_full_FIXED.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UA8c4ThZ92Sf",
        "colab_type": "text"
      },
      "source": [
        "### Load Fixed Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srRTZPpa90zM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPU_train_full = pd.read_csv('EPU_complete_train_full_FIXED.csv')\n",
        "EPU_test_full = pd.read_csv('EPU_complete_test_full_FIXED.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1p_H8dcr-QFD",
        "colab": {}
      },
      "source": [
        "labels_train = EPU_train[['Label']]\n",
        "labels_test = EPU_test[['Label']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v91pWd-4M2c2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPU_train_full = pd.merge(EPU_train_full, labels_train, left_index=True, right_index=True)\n",
        "EPU_test_full = pd.merge(EPU_test_full, labels_test, left_index=True, right_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWYKomeIexMi",
        "colab_type": "text"
      },
      "source": [
        "## Scoring (Rouge / Bleu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cU93YZnV5bXe",
        "colab_type": "text"
      },
      "source": [
        "### Apply ROUGE Scoring Row-Wise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXxzgIX95bHO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rouge = Rouge()\n",
        "def rouge_scoring(row):\n",
        "\n",
        "  reference = str(row['Headline'])\n",
        "  candidate = str(row['Bench_Seed'])\n",
        "  score = rouge.get_scores(candidate, reference)[0]['rouge-1']['r']\n",
        "\n",
        "  return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0s1LKGR9QaE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPU_train_full['ROUGE'] = EPU_train_full.apply(lambda row: rouge_scoring(row), axis=1)\n",
        "EPU_test_full['ROUGE'] = EPU_test_full.apply(lambda row: rouge_scoring(row), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AMn4KMH5f4R",
        "colab_type": "text"
      },
      "source": [
        "### Apply BLEU Scoring Row-Wise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryqE5QV76-CM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bleu_scoring(row):\n",
        "\n",
        "  reference = row['Headline']\n",
        "  candidate = row['Bench_Seed']\n",
        "\n",
        "  reference = [str(reference).split()]\n",
        "  candidate = str(candidate).split()\n",
        "  score = sentence_bleu(reference, candidate, weights=(1, 0, 0, 0))\n",
        "\n",
        "  return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ct8EqeWF5gV8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPU_train_full['BLEU'] = EPU_train_full.apply(lambda row: bleu_scoring(row), axis=1)\n",
        "EPU_test_full['BLEU'] = EPU_test_full.apply(lambda row: bleu_scoring(row), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZwOerjN91Au",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_first_20(row):\n",
        "\n",
        "  first_20 = ' '.join([word for i, word in enumerate(row['Article'].split()) if i <=20])\n",
        "  return first_20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhfiKhBQ9oo0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPU_test_full['Bench_Seed'] = EPU_test_full.apply(lambda row: get_first_20(row), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6i-xwhV-sRN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPU_test_full['Baseline_ROUGE'] = EPU_test_full.apply(lambda row: rouge_scoring(row), axis=1)\n",
        "EPU_test_full['Baseline_BLEU'] = EPU_test_full.apply(lambda row: bleu_scoring(row), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbzkTlur_EGy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPU_test_full.to_csv('EPU_complete_train_full_FIXED_W_SCORES.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pl6fXnWKxc2I",
        "colab_type": "text"
      },
      "source": [
        "# Classifier Networks for EPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3ZejkVhL2hNw"
      },
      "source": [
        "## Test / Train Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pnR6e3tc2hN0"
      },
      "source": [
        "### Load Checkpoint Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TJUOfcDo2hN1",
        "colab": {}
      },
      "source": [
        "os.chdir('/gdrive/My Drive/colab_notebooks/information_systems/data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QYOcrxv12hN3"
      },
      "source": [
        "##### Original Data Frame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nyPEOLd82hN4",
        "colab": {}
      },
      "source": [
        "EPU_checkpoint = pd.read_csv('EPU_checkpoint_full_new.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8VWEuzT_2hN6"
      },
      "source": [
        "### Slice Down to `Article` & `Headline` Columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6emWyuLefZHE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPU_cv_frame = EPU_checkpoint[['Newspaper', 'Date', 'Headline', 'Article', 'Label']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wjeJNpFx2hN6",
        "colab": {}
      },
      "source": [
        "EPU_seq = EPU_checkpoint[['Headline', 'Label']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJYyGfAP5Izd",
        "colab_type": "text"
      },
      "source": [
        "### Read `Train` & `Test` Frames w/ Prediticted Headlines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ug74Dk6i5IY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPU_train_full = pd.read_csv('EPU_complete_train_full_FIXED.csv')\n",
        "EPU_test_full = pd.read_csv('EPU_complete_test_full_FIXED.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGwoTXoK5UsI",
        "colab_type": "text"
      },
      "source": [
        "### Merge Tables on Article Text to Transfer Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CfUeFae7zAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPU_seq['Headline'] = EPU_seq['Headline'].apply(lambda headline: headline.replace('tokenstart ', '').rstrip())\n",
        "EPU_seq['Headline'] = EPU_seq['Headline'].apply(lambda headline: headline.replace('tokenend', '').rstrip())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZcH6SSu9Usf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPU_train_full['Headline'] = EPU_train_full['Headline'].apply(lambda headline: headline.rstrip())\n",
        "EPU_test_full['Headline'] = EPU_test_full['Headline'].apply(lambda headline: headline.rstrip())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqmR-Wfd5vQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPU_test_full = EPU_test_full.merge(EPU_seq, on='Headline')[['Article', 'Headline', 'Headline_Gen', 'Label']]\n",
        "EPU_train_full = EPU_train_full.merge(EPU_seq, on='Headline')[['Article', 'Headline', 'Headline_Gen', 'Label']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TgMIknvGHx0",
        "colab_type": "text"
      },
      "source": [
        "### Remove Target Leak Risks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhDRjAVRGQ0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_target_leak(article):\n",
        "  \n",
        "  leak_strings = ['uncertainty', 'uncertain', 'policy']\n",
        "  leak_strings_sub = [' ' + word for word in leak_strings]\n",
        "  leak_strings_sub.extend([word + ' ' for word in leak_strings])\n",
        "\n",
        "  article_out = article\n",
        "  for word in leak_strings_sub:\n",
        "    article_out = article_out.replace(word, '')\n",
        "\n",
        "  return article_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D57xwBLUgbv8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPU_cv_frame['Article'] = EPU_cv_frame['Article'].apply(lambda article: clean_target_leak(article))\n",
        "EPU_cv_frame['Headline'] = EPU_cv_frame['Headline'].apply(lambda headline: clean_target_leak(headline))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QILB6MHTGIdV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPU_train_full['Article'] = EPU_train_full['Article'].apply(lambda article: clean_target_leak(article))\n",
        "EPU_train_full['Headline'] = EPU_train_full['Headline'].apply(lambda headline: clean_target_leak(headline))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W16x4sTQOoNq",
        "colab_type": "text"
      },
      "source": [
        "### Combine `Headline` & `Article` Fields"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtnUDvWoglWI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPU_cv_frame['combined_org'] = EPU_cv_frame.apply(lambda row: row['Headline'] + ' ' + row['Article'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFFKmLkUAPFD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPU_train_full['combined_org'] = EPU_train_full.apply(lambda row: row['Headline'] + ' ' + row['Article'], axis=1)\n",
        "EPU_test_full['combined_org'] = EPU_test_full.apply(lambda row: row['Headline'] + ' ' + row['Article'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HLl7MMwARJ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPU_train_full['combined_gen'] = EPU_train_full.apply(lambda row: str(row['Headline_Gen']) + ' ' + row['Article'], axis=1)\n",
        "EPU_test_full['combined_gen'] = EPU_test_full.apply(lambda row: str(row['Headline_Gen']) + ' ' + row['Article'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Z7F90iBW2hOB"
      },
      "source": [
        "## Tokeniser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m8MbTf0Y2hOB",
        "colab": {}
      },
      "source": [
        "max_length_article = 550\n",
        "max_length_combined = 570"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vXchsCil2hOD"
      },
      "source": [
        "### Run Tokenisers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkjsaeHpgtsh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv_tokeniser = Tokenizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ds5m8RoRgti2",
        "colab_type": "code",
        "outputId": "62824848-5aea-4f59-a40e-e466dd29ef62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cv_tokeniser.fit_on_texts(list(EPU_cv_frame['combined_org']))\n",
        "cv_sequences = cv_tokeniser.texts_to_sequences(EPU_cv_frame['combined_org'])\n",
        "cv_sequences = pad_sequences(cv_sequences, maxlen=max_length_combined, padding='post')\n",
        "\n",
        "cv_vocabulary = cv_tokeniser.word_index\n",
        "cv_vocabulary_size = len(cv_tokeniser.word_index) + 1\n",
        "print(f'article vocabulary size: {cv_vocabulary_size}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "article vocabulary size: 55282\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ujULKd5h2hOD",
        "colab": {}
      },
      "source": [
        "article_tokeniser = Tokenizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CGJsxX2n2hOF",
        "outputId": "a1590363-7198-4532-ed71-82f1af44b878",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "article_tokeniser.fit_on_texts(list(EPU_train_full['Article']))\n",
        "train_sequences_article = article_tokeniser.texts_to_sequences(EPU_train_full['Article'])\n",
        "test_sequences_article = article_tokeniser.texts_to_sequences(EPU_test_full['Article'])\n",
        "\n",
        "train_sequences_article = pad_sequences(train_sequences_article, maxlen=max_length_article, padding='post')\n",
        "test_sequences_article = pad_sequences(test_sequences_article, maxlen=max_length_article, padding='post')\n",
        "\n",
        "article_vocabulary = article_tokeniser.word_index\n",
        "article_vocabulary_size = len(article_tokeniser.word_index) + 1\n",
        "print(f'article vocabulary size: {article_vocabulary_size}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "article vocabulary size: 53759\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SrDWY0Wx2hOG",
        "colab": {}
      },
      "source": [
        "combined_tokeniser_original = Tokenizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "964eb217-b0f3-473e-e5c0-b95b10ec74af",
        "id": "v07ohS6L2hOI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "combined_tokeniser_original.fit_on_texts(list(EPU_train_full['combined_org']))\n",
        "train_sequences_combined_org = combined_tokeniser_original.texts_to_sequences(EPU_train_full['combined_org'])\n",
        "test_sequences_combined_org = combined_tokeniser_original.texts_to_sequences(EPU_test_full['combined_org'])\n",
        "\n",
        "train_sequences_combined_org = pad_sequences(train_sequences_combined_org, maxlen=max_length_combined, padding='post')\n",
        "test_sequences_combined_org = pad_sequences(test_sequences_combined_org, maxlen=max_length_combined, padding='post')\n",
        "\n",
        "combined_vocabulary_org = combined_tokeniser_original.word_index\n",
        "combined_vocabulary_org_size = len(combined_tokeniser_original.word_index) + 1\n",
        "print(f'combined vocabulary size: {combined_vocabulary_org_size}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "combined vocabulary size: 54632\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bOvLfMo3_YF1",
        "colab": {}
      },
      "source": [
        "combined_tokeniser_generated = Tokenizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "efc47a89-8905-4d23-f8a0-b8e6251696b1",
        "id": "wXbqpyFy_YF5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "combined_tokeniser_generated.fit_on_texts(list(EPU_train_full['combined_gen']))\n",
        "train_sequences_combined_gen = combined_tokeniser_generated.texts_to_sequences(EPU_train_full['combined_gen'])\n",
        "test_sequences_combined_gen = combined_tokeniser_generated.texts_to_sequences(EPU_test_full['combined_gen'])\n",
        "\n",
        "train_sequences_combined_gen = pad_sequences(train_sequences_combined_gen, maxlen=max_length_combined, padding='post')\n",
        "test_sequences_combined_gen = pad_sequences(test_sequences_combined_gen, maxlen=max_length_combined, padding='post')\n",
        "\n",
        "combined_vocabulary_gen = combined_tokeniser_generated.word_index\n",
        "combined_vocabulary_gen_size = len(combined_tokeniser_generated.word_index) + 1\n",
        "print(f'combined vocabulary size: {combined_vocabulary_gen_size}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "combined vocabulary size: 53965\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9ztp-30R2hOM"
      },
      "source": [
        "### Pickle `Tokeniser` Objects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QzmWM2JH2hON",
        "colab": {}
      },
      "source": [
        "os.chdir('/gdrive/My Drive/colab_notebooks/information_systems/data/pickled_tokenisers/classifier')\n",
        "\n",
        "### CV\n",
        "\n",
        "with open('tokenizer_cv.pkl', 'wb') as cv_tokeniser_out:\n",
        "    pickle.dump(cv_tokeniser, cv_tokeniser_out, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "with open('cv_sequences.pkl', 'wb') as cv_sequences_out:\n",
        "    pickle.dump(cv_sequences, cv_sequences_out, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "### Article\n",
        "\n",
        "with open('tokenizer_article.pkl', 'wb') as article_tokeniser_out:\n",
        "    pickle.dump(article_tokeniser, article_tokeniser_out, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "with open('train_sequences_article.pkl', 'wb') as train_sequences_article_out:\n",
        "    pickle.dump(train_sequences_article, train_sequences_article_out, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    \n",
        "with open('test_sequences_article.pkl', 'wb') as test_sequences_article_out:\n",
        "    pickle.dump(test_sequences_article, test_sequences_article_out, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "### Combined Original\n",
        "\n",
        "with open('tokenizer_combined_org.pkl', 'wb') as combined_tokeniser_org_out:\n",
        "    pickle.dump(combined_tokeniser_original, combined_tokeniser_org_out, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "with open('train_sequences_combined_org.pkl', 'wb') as train_sequences_combined_org_out:\n",
        "    pickle.dump(train_sequences_combined_org, train_sequences_combined_org_out, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "with open('test_sequences_combined_org.pkl', 'wb') as test_sequences_combined_org_out:\n",
        "    pickle.dump(test_sequences_combined_org, test_sequences_combined_org_out, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "### Combined Generated\n",
        "\n",
        "with open('tokenizer_combined_gen.pkl', 'wb') as combined_tokeniser_gen_out:\n",
        "    pickle.dump(combined_tokeniser_generated, combined_tokeniser_gen_out, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "with open('train_sequences_combined_gen.pkl', 'wb') as train_sequences_combined_gen_out:\n",
        "    pickle.dump(train_sequences_combined_gen, train_sequences_combined_gen_out, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "with open('test_sequences_combined_gen.pkl', 'wb') as test_sequences_combined_gen_out:\n",
        "    pickle.dump(test_sequences_combined_gen, test_sequences_combined_gen_out, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xBUtRHhW2hOP"
      },
      "source": [
        "### Load `Tokeniser` Pickle Objects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sDKQgTul2hOP",
        "colab": {}
      },
      "source": [
        "os.chdir('/gdrive/My Drive/colab_notebooks/information_systems/data/pickled_tokenisers/classifier')\n",
        "\n",
        "### CV\n",
        "\n",
        "with open('tokenizer_cv.pkl', 'rb') as cv_tokeniser_in:\n",
        "    cv_tokeniser = pickle.load(cv_tokeniser_in)\n",
        "    cv_vocabulary = cv_tokeniser.word_index\n",
        "    cv_vocabulary_size = len(cv_tokeniser.word_index) + 1\n",
        "\n",
        "with open('cv_sequences.pkl', 'rb') as cv_sequences_in:\n",
        "    cv_sequences = pickle.load(cv_sequences_in)\n",
        "\n",
        "### Article\n",
        "\n",
        "with open('tokenizer_article.pkl', 'rb') as article_tokeniser_in:\n",
        "    article_tokeniser = pickle.load(article_tokeniser_in)\n",
        "    article_vocabulary = article_tokeniser.word_index\n",
        "    article_vocabulary_size = len(article_tokeniser.word_index) + 1\n",
        "\n",
        "with open('train_sequences_article.pkl', 'rb') as train_sequences_article_in:\n",
        "    train_sequences_article = pickle.load(train_sequences_article_in)\n",
        "\n",
        "with open('test_sequences_article.pkl', 'rb') as test_sequences_article_in:\n",
        "    test_sequences_article = pickle.load(test_sequences_article_in)\n",
        "\n",
        "### Combined Original\n",
        "\n",
        "with open('tokenizer_combined_org.pkl', 'rb') as combined_org_tokeniser_in:\n",
        "    combined_tokeniser_original = pickle.load(combined_org_tokeniser_in)\n",
        "    combined_vocabulary_org = combined_tokeniser_original.word_index\n",
        "    combined_vocabulary_org_size = len(combined_tokeniser_original.word_index) + 1\n",
        "\n",
        "with open('train_sequences_combined_org.pkl', 'rb') as train_sequences_combined_org_in:\n",
        "    train_sequences_combined_org = pickle.load(train_sequences_combined_org_in)\n",
        "\n",
        "with open('test_sequences_combined_org.pkl', 'rb') as test_sequences_combined_org_in:\n",
        "    test_sequences_combined_org = pickle.load(test_sequences_combined_org_in)\n",
        "\n",
        "### Combined Generated\n",
        "\n",
        "with open('tokenizer_combined_gen.pkl', 'rb') as combined_gen_tokeniser_in:\n",
        "    combined_tokeniser_generated = pickle.load(combined_gen_tokeniser_in)\n",
        "    combined_vocabulary_gen = combined_tokeniser_generated.word_index\n",
        "    combined_vocabulary_gen_size = len(combined_tokeniser_generated.word_index) + 1\n",
        "\n",
        "with open('train_sequences_combined_gen.pkl', 'rb') as train_sequences_combined_gen_in:\n",
        "    train_sequences_combined_gen = pickle.load(train_sequences_combined_gen_in)\n",
        "\n",
        "with open('test_sequences_combined_gen.pkl', 'rb') as test_sequences_combined_gen_in:\n",
        "    test_sequences_combined_gen = pickle.load(test_sequences_combined_gen_in)\n",
        "\n",
        "os.chdir('/gdrive/My Drive/colab_notebooks/information_systems/data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3Otuo61YE_Y8"
      },
      "source": [
        "## Pre-Trained Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "urt0547tE_ZO"
      },
      "source": [
        "#### Define Values for Embedding Logic / Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4b2Q2n7DE_ZP",
        "colab": {}
      },
      "source": [
        "embedding_dimension = 768"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XBppRydoE_ZQ"
      },
      "source": [
        "#### Read GPT-2 Model / Tokeniser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J062RDyZE_ZR",
        "colab": {}
      },
      "source": [
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "tokeniser = GPT2Tokenizer.from_pretrained('gpt2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uNRQEBsaE_ZS",
        "colab": {}
      },
      "source": [
        "word_embeddings = model.transformer.wte.weight\n",
        "position_embeddings = model.transformer.wpe.weight"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wyWg51kkiOkP"
      },
      "source": [
        "#### Prepare Embedding Matrix – CV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4uQ6h9gFiOkS",
        "colab": {}
      },
      "source": [
        "count_words = cv_vocabulary_size\n",
        "embedding_matrix = np.zeros((count_words, embedding_dimension))\n",
        "for word, i in cv_vocabulary.items():\n",
        "    if i >= cv_vocabulary_size:\n",
        "        continue\n",
        "\n",
        "    text_index = tokeniser.encode(word, add_prefix_space=True)\n",
        "    embedding_vector_tensor = model.transformer.wte.weight[text_index, :]\n",
        "    embedding_vector_np = embedding_vector_tensor.detach().numpy()[0]\n",
        "    if embedding_vector_np is not None:\n",
        "        embedding_matrix[i] = embedding_vector_np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KGA9FcB3iOkW",
        "colab": {}
      },
      "source": [
        "embedding_layer_cv = Embedding(count_words, embedding_dimension,\n",
        "                               embeddings_initializer=Constant(embedding_matrix),\n",
        "                               input_length=max_length_combined,\n",
        "                               trainable=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yPcHXn-rE_ZV"
      },
      "source": [
        "#### Prepare Embedding Matrix – Article"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C9rIh4s8E_ZW",
        "colab": {}
      },
      "source": [
        "count_words = article_vocabulary_size\n",
        "embedding_matrix = np.zeros((count_words, embedding_dimension))\n",
        "for word, i in article_vocabulary.items():\n",
        "    if i >= article_vocabulary_size:\n",
        "        continue\n",
        "\n",
        "    text_index = tokeniser.encode(word, add_prefix_space=True)\n",
        "    embedding_vector_tensor = model.transformer.wte.weight[text_index, :]\n",
        "    embedding_vector_np = embedding_vector_tensor.detach().numpy()[0]\n",
        "    if embedding_vector_np is not None:\n",
        "        embedding_matrix[i] = embedding_vector_np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BzaAKeZ_E_ZX",
        "colab": {}
      },
      "source": [
        "embedding_layer_article = Embedding(count_words, embedding_dimension,\n",
        "                                    embeddings_initializer=Constant(embedding_matrix),\n",
        "                                    input_length=max_length_article,\n",
        "                                    trainable=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HTdQXCryE_ZZ"
      },
      "source": [
        "#### Prepare Embedding Matrix – Combined Original"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vvadSv93E_Zb",
        "colab": {}
      },
      "source": [
        "count_words = combined_vocabulary_org_size\n",
        "embedding_matrix = np.zeros((count_words, embedding_dimension))\n",
        "for word, i in combined_vocabulary_org.items():\n",
        "    if i >= combined_vocabulary_org_size:\n",
        "        continue\n",
        "\n",
        "    text_index = tokeniser.encode(word, add_prefix_space=True)\n",
        "    embedding_vector_tensor = model.transformer.wte.weight[text_index, :]\n",
        "    embedding_vector_np = embedding_vector_tensor.detach().numpy()[0]\n",
        "    if embedding_vector_np is not None:\n",
        "        embedding_matrix[i] = embedding_vector_np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9rv-JZ7XE_Zd",
        "colab": {}
      },
      "source": [
        "embedding_layer_combined_org = Embedding(count_words, embedding_dimension,\n",
        "                                         embeddings_initializer=Constant(embedding_matrix),\n",
        "                                         input_length=max_length_combined,\n",
        "                                         trainable=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vD9R6SjVGIdd"
      },
      "source": [
        "#### Prepare Embedding Matrix – Combined Generated"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sEdgNRS2GIdg",
        "colab": {}
      },
      "source": [
        "count_words = combined_vocabulary_gen_size\n",
        "embedding_matrix = np.zeros((count_words, embedding_dimension))\n",
        "for word, i in combined_vocabulary_gen.items():\n",
        "    if i >= combined_vocabulary_gen_size:\n",
        "        continue\n",
        "\n",
        "    text_index = tokeniser.encode(word, add_prefix_space=True)\n",
        "    embedding_vector_tensor = model.transformer.wte.weight[text_index, :]\n",
        "    embedding_vector_np = embedding_vector_tensor.detach().numpy()[0]\n",
        "    if embedding_vector_np is not None:\n",
        "        embedding_matrix[i] = embedding_vector_np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s1FwjvMSGIdi",
        "colab": {}
      },
      "source": [
        "embedding_layer_combined_gen = Embedding(count_words, embedding_dimension,\n",
        "                                         embeddings_initializer=Constant(embedding_matrix),\n",
        "                                         input_length=max_length_combined,\n",
        "                                         trainable=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amjVSGztK5WY",
        "colab_type": "text"
      },
      "source": [
        "## Classifier w/ Original Headlines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skc0nUbZPvAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_GRU_Keras_original():\n",
        "  \"\"\"Constructor for GRU network with original headlines combined with articles.\"\"\"\n",
        "  \n",
        "  model_gpt = Sequential() \n",
        "  model_gpt.add(embedding_layer_combined_org)\n",
        "  model_gpt.add(Bidirectional(CuDNNGRU(180, return_sequences=True)))\n",
        "\n",
        "  model_gpt.add(Dropout(0.3))\n",
        "  model_gpt.add(Attention(max_length_combined))\n",
        "\n",
        "  model_gpt.add(Dense(1, activation=\"sigmoid\"))\n",
        "  model_gpt.compile(loss=\"binary_crossentropy\", optimizer='rmsprop', metrics=[\"accuracy\"])\n",
        "  model_gpt.summary()\n",
        "\n",
        "  return model_gpt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gl8oFqagJo9Q",
        "colab_type": "text"
      },
      "source": [
        "### Fit Model w/ Original Headlines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBXBaMY1Cwzi",
        "colab_type": "code",
        "outputId": "07c993a7-4350-4190-a776-0f6e62e48bb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        }
      },
      "source": [
        "os.chdir('/gdrive/My Drive/colab_notebooks/information_systems/data/model_checkpoints')\n",
        "callbacks = [ModelCheckpoint(filepath='seq2seq_classifier_original_{epoch:02d}-{val_loss:.2f}.hdf5'), \n",
        "             EarlyStopping(monitor='val_loss', patience=3, verbose=1, min_delta=1e-4, restore_best_weights=True)]\n",
        "\n",
        "model_GRU_Keras = build_GRU_Keras_original()\n",
        "model_GRU_Keras.fit(train_sequences_combined_org, EPU_train_full['Label'].values, epochs=15, \n",
        "                    verbose=1, batch_size=56, validation_split=0.3, shuffle=True, callbacks=callbacks)\n",
        "\n",
        "model_GRU_Keras.save('seq2seq_classifier_original_04.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Entity <bound method Attention.call of <attention_02.Attention object at 0x7f85991c0240>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Attention.call of <attention_02.Attention object at 0x7f85991c0240>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 570, 768)          41957376  \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 570, 360)          1026000   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 570, 360)          0         \n",
            "_________________________________________________________________\n",
            "attention_2 (Attention)      (None, 360)               930       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 361       \n",
            "=================================================================\n",
            "Total params: 42,984,667\n",
            "Trainable params: 1,027,291\n",
            "Non-trainable params: 41,957,376\n",
            "_________________________________________________________________\n",
            "Train on 177652 samples, validate on 76137 samples\n",
            "Epoch 1/15\n",
            "177652/177652 [==============================] - 408s 2ms/sample - loss: 0.0458 - acc: 0.9892 - val_loss: 0.0340 - val_acc: 0.9914\n",
            "Epoch 2/15\n",
            "177652/177652 [==============================] - 409s 2ms/sample - loss: 0.0341 - acc: 0.9919 - val_loss: 0.0295 - val_acc: 0.9930\n",
            "Epoch 3/15\n",
            "177652/177652 [==============================] - 407s 2ms/sample - loss: 0.0302 - acc: 0.9931 - val_loss: 0.0297 - val_acc: 0.9932\n",
            "Epoch 4/15\n",
            "177652/177652 [==============================] - 409s 2ms/sample - loss: 0.0270 - acc: 0.9939 - val_loss: 0.0286 - val_acc: 0.9936\n",
            "Epoch 5/15\n",
            "177652/177652 [==============================] - 409s 2ms/sample - loss: 0.0243 - acc: 0.9945 - val_loss: 0.0300 - val_acc: 0.9936\n",
            "Epoch 6/15\n",
            "177652/177652 [==============================] - 409s 2ms/sample - loss: 0.0214 - acc: 0.9950 - val_loss: 0.0303 - val_acc: 0.9933\n",
            "Epoch 7/15\n",
            "177632/177652 [============================>.] - ETA: 0s - loss: 0.0183 - acc: 0.9957Restoring model weights from the end of the best epoch.\n",
            "177652/177652 [==============================] - 408s 2ms/sample - loss: 0.0183 - acc: 0.9957 - val_loss: 0.0328 - val_acc: 0.9932\n",
            "Epoch 00007: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgKtG-_30n5F",
        "colab_type": "text"
      },
      "source": [
        "#### Calculate ROC Curve and AUC Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tc5zHLMHBKbs",
        "colab_type": "code",
        "outputId": "a5c5e92a-b04a-4b78-fc1f-e2f829a4670a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "fpr, tpr, thresholds = metrics.roc_curve(EPU_test_full['Label'].values, model_GRU_Keras.predict(test_sequences_combined_org))\n",
        "metrics.auc(fpr, tpr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9546264849790569"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KCxKGueHLCHc"
      },
      "source": [
        "## Classifier w/ Generated Headlines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oc40lzIKTMDs",
        "colab": {}
      },
      "source": [
        "def build_GRU_Keras_generated():\n",
        "  \"\"\"Constructor for GRU network with original headlines combined with articles.\"\"\"\n",
        "  \n",
        "  model_gpt = Sequential() \n",
        "  model_gpt.add(embedding_layer_combined_gen)\n",
        "  model_gpt.add(Bidirectional(CuDNNGRU(180, return_sequences=True)))\n",
        "\n",
        "  model_gpt.add(Dropout(0.3))\n",
        "  model_gpt.add(Attention(max_length_combined))\n",
        "\n",
        "  model_gpt.add(Dense(1, activation=\"sigmoid\"))\n",
        "  model_gpt.compile(loss=\"binary_crossentropy\", optimizer='rmsprop', metrics=[\"accuracy\"])\n",
        "  model_gpt.summary()\n",
        "\n",
        "  return model_gpt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FKXqQUL9TMDy"
      },
      "source": [
        "### Fit Model w/ Generated Headlines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ff9991a7-dde0-4dcb-c8e2-c014407b6ca5",
        "id": "D5vKDLKtTMDz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        }
      },
      "source": [
        "os.chdir('/gdrive/My Drive/colab_notebooks/information_systems/data/model_checkpoints')\n",
        "callbacks = [ModelCheckpoint(filepath='seq2seq_classifier_generated_{epoch:02d}-{val_loss:.2f}.hdf5'), \n",
        "             EarlyStopping(monitor='val_loss', patience=3, verbose=1, min_delta=1e-4, restore_best_weights=True)]\n",
        "\n",
        "model_GRU_Keras = build_GRU_Keras_generated()\n",
        "model_GRU_Keras.fit(train_sequences_combined_gen, EPU_train_full['Label'].values, epochs=15, \n",
        "                    verbose=1, batch_size=56, validation_split=0.3, shuffle=True, callbacks=callbacks)\n",
        "\n",
        "model_GRU_Keras.save('seq2seq_classifier_generated_01.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Entity <bound method Attention.call of <attention_02.Attention object at 0x7f859a379710>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Attention.call of <attention_02.Attention object at 0x7f859a379710>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 570, 768)          41445120  \n",
            "_________________________________________________________________\n",
            "bidirectional_4 (Bidirection (None, 570, 360)          1026000   \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 570, 360)          0         \n",
            "_________________________________________________________________\n",
            "attention_3 (Attention)      (None, 360)               930       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 361       \n",
            "=================================================================\n",
            "Total params: 42,472,411\n",
            "Trainable params: 1,027,291\n",
            "Non-trainable params: 41,445,120\n",
            "_________________________________________________________________\n",
            "Train on 177652 samples, validate on 76137 samples\n",
            "Epoch 1/15\n",
            "177652/177652 [==============================] - 408s 2ms/sample - loss: 0.0425 - acc: 0.9898 - val_loss: 0.0325 - val_acc: 0.9922\n",
            "Epoch 2/15\n",
            "177652/177652 [==============================] - 405s 2ms/sample - loss: 0.0321 - acc: 0.9926 - val_loss: 0.0285 - val_acc: 0.9930\n",
            "Epoch 3/15\n",
            "177652/177652 [==============================] - 404s 2ms/sample - loss: 0.0277 - acc: 0.9936 - val_loss: 0.0281 - val_acc: 0.9932\n",
            "Epoch 4/15\n",
            "177652/177652 [==============================] - 406s 2ms/sample - loss: 0.0249 - acc: 0.9943 - val_loss: 0.0282 - val_acc: 0.9933\n",
            "Epoch 5/15\n",
            "177652/177652 [==============================] - 407s 2ms/sample - loss: 0.0220 - acc: 0.9948 - val_loss: 0.0285 - val_acc: 0.9938\n",
            "Epoch 6/15\n",
            "177632/177652 [============================>.] - ETA: 0s - loss: 0.0185 - acc: 0.9954Restoring model weights from the end of the best epoch.\n",
            "177652/177652 [==============================] - 406s 2ms/sample - loss: 0.0185 - acc: 0.9954 - val_loss: 0.0295 - val_acc: 0.9935\n",
            "Epoch 00006: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fLSI7B8nTMD3"
      },
      "source": [
        "#### Calculate ROC Curve and AUC Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "20e0ea3d-f5dd-41c9-ff04-b497e20d29ff",
        "id": "C5CJcb0uTMD4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "fpr, tpr, thresholds = metrics.roc_curve(EPU_test_full['Label'].values, model_GRU_Keras.predict(test_sequences_combined_gen))\n",
        "metrics.auc(fpr, tpr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.955308939361928"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOdx-ZtJ4gtc",
        "colab_type": "text"
      },
      "source": [
        "### Remove Target Leak & Re-Tokenise / Embed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUEQhLVU4gbD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPU_train_full['combined_gen'] = EPU_train_full['combined_gen'].apply(lambda combined_text: clean_target_leak(combined_text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oXjNYOm52AQ",
        "colab_type": "text"
      },
      "source": [
        "#### Tokenise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "58qWaIkL5jAk",
        "colab": {}
      },
      "source": [
        "combined_tokeniser_generated = Tokenizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c812ca38-868c-4781-b363-f5fbc3f4871c",
        "id": "WOfVeL0u5jAp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "combined_tokeniser_generated.fit_on_texts(list(EPU_train_full['combined_gen']))\n",
        "train_sequences_combined_gen = combined_tokeniser_generated.texts_to_sequences(EPU_train_full['combined_gen'])\n",
        "test_sequences_combined_gen = combined_tokeniser_generated.texts_to_sequences(EPU_test_full['combined_gen'])\n",
        "\n",
        "train_sequences_combined_gen = pad_sequences(train_sequences_combined_gen, maxlen=max_length_combined, padding='post')\n",
        "test_sequences_combined_gen = pad_sequences(test_sequences_combined_gen, maxlen=max_length_combined, padding='post')\n",
        "\n",
        "combined_vocabulary_gen = combined_tokeniser_generated.word_index\n",
        "combined_vocabulary_gen_size = len(combined_tokeniser_generated.word_index) + 1\n",
        "print(f'combined vocabulary size: {combined_vocabulary_gen_size}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "combined vocabulary size: 53967\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ShZAZj5a5ynl"
      },
      "source": [
        "#### Prepare Embedding Matrix – Combined Generated"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c_IDBJAb5ynm",
        "colab": {}
      },
      "source": [
        "count_words = combined_vocabulary_gen_size\n",
        "embedding_matrix = np.zeros((count_words, embedding_dimension))\n",
        "for word, i in combined_vocabulary_gen.items():\n",
        "    if i >= combined_vocabulary_gen_size:\n",
        "        continue\n",
        "\n",
        "    text_index = tokeniser.encode(word, add_prefix_space=True)\n",
        "    embedding_vector_tensor = model.transformer.wte.weight[text_index, :]\n",
        "    embedding_vector_np = embedding_vector_tensor.detach().numpy()[0]\n",
        "    if embedding_vector_np is not None:\n",
        "        embedding_matrix[i] = embedding_vector_np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_BjritLv5ynp",
        "colab": {}
      },
      "source": [
        "embedding_layer_combined_gen = Embedding(count_words, embedding_dimension,\n",
        "                                         embeddings_initializer=Constant(embedding_matrix),\n",
        "                                         input_length=max_length_combined,\n",
        "                                         trainable=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKYRL5gd5_9H",
        "colab_type": "text"
      },
      "source": [
        "### Run Model Again"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0786164b-d7a8-421f-dbd4-1ddeda73931e",
        "id": "oKPKuWyM5-7g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        }
      },
      "source": [
        "os.chdir('/gdrive/My Drive/colab_notebooks/information_systems/data/model_checkpoints')\n",
        "callbacks = [ModelCheckpoint(filepath='seq2seq_classifier_generated_{epoch:02d}-{val_loss:.2f}.hdf5'), \n",
        "             EarlyStopping(monitor='val_loss', patience=3, verbose=1, min_delta=1e-4, restore_best_weights=True)]\n",
        "\n",
        "model_GRU_Keras = build_GRU_Keras_generated()\n",
        "model_GRU_Keras.fit(train_sequences_combined_gen, EPU_train_full['Label'].values, epochs=15, \n",
        "                    verbose=1, batch_size=56, validation_split=0.3, shuffle=True, callbacks=callbacks)\n",
        "\n",
        "model_GRU_Keras.save('seq2seq_classifier_generated_02.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Entity <bound method Attention.call of <attention_02.Attention object at 0x7f85978aad68>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Attention.call of <attention_02.Attention object at 0x7f85978aad68>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, 570, 768)          41446656  \n",
            "_________________________________________________________________\n",
            "bidirectional_5 (Bidirection (None, 570, 360)          1026000   \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 570, 360)          0         \n",
            "_________________________________________________________________\n",
            "attention_4 (Attention)      (None, 360)               930       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 361       \n",
            "=================================================================\n",
            "Total params: 42,473,947\n",
            "Trainable params: 1,027,291\n",
            "Non-trainable params: 41,446,656\n",
            "_________________________________________________________________\n",
            "Train on 177652 samples, validate on 76137 samples\n",
            "Epoch 1/15\n",
            "177652/177652 [==============================] - 418s 2ms/sample - loss: 0.0451 - acc: 0.9896 - val_loss: 0.0356 - val_acc: 0.9914\n",
            "Epoch 2/15\n",
            "177652/177652 [==============================] - 413s 2ms/sample - loss: 0.0335 - acc: 0.9920 - val_loss: 0.0293 - val_acc: 0.9929\n",
            "Epoch 3/15\n",
            "177652/177652 [==============================] - 406s 2ms/sample - loss: 0.0298 - acc: 0.9929 - val_loss: 0.0293 - val_acc: 0.9931\n",
            "Epoch 4/15\n",
            "177652/177652 [==============================] - 407s 2ms/sample - loss: 0.0271 - acc: 0.9938 - val_loss: 0.0291 - val_acc: 0.9935\n",
            "Epoch 5/15\n",
            "177652/177652 [==============================] - 409s 2ms/sample - loss: 0.0244 - acc: 0.9944 - val_loss: 0.0295 - val_acc: 0.9931\n",
            "Epoch 6/15\n",
            "177652/177652 [==============================] - 408s 2ms/sample - loss: 0.0210 - acc: 0.9948 - val_loss: 0.0305 - val_acc: 0.9935\n",
            "Epoch 7/15\n",
            "177632/177652 [============================>.] - ETA: 0s - loss: 0.0176 - acc: 0.9956Restoring model weights from the end of the best epoch.\n",
            "177652/177652 [==============================] - 407s 2ms/sample - loss: 0.0176 - acc: 0.9956 - val_loss: 0.0365 - val_acc: 0.9935\n",
            "Epoch 00007: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7B8agBsf5-7n"
      },
      "source": [
        "#### Calculate ROC Curve and AUC Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "58db2637-d196-400b-f46f-89450e2e887f",
        "id": "Y8rlmxxu5-7n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "fpr, tpr, thresholds = metrics.roc_curve(EPU_test_full['Label'].values, model_GRU_Keras.predict(test_sequences_combined_gen))\n",
        "metrics.auc(fpr, tpr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9369845361442117"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPfwRuHyfsTg",
        "colab_type": "text"
      },
      "source": [
        "## Classifier w/o Headlines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WXFFTUWdTNSg",
        "colab": {}
      },
      "source": [
        "def build_GRU_Keras_article():\n",
        "  \"\"\"Constructor for GRU network with original headlines combined with articles.\"\"\"\n",
        "  \n",
        "  model_gpt = Sequential() \n",
        "  model_gpt.add(embedding_layer_article)\n",
        "  model_gpt.add(Bidirectional(CuDNNGRU(180, return_sequences=True)))\n",
        "\n",
        "  model_gpt.add(Dropout(0.3))\n",
        "  model_gpt.add(Attention(max_length_article))\n",
        "\n",
        "  model_gpt.add(Dense(1, activation=\"sigmoid\"))\n",
        "  model_gpt.compile(loss=\"binary_crossentropy\", optimizer='rmsprop', metrics=[\"accuracy\"])\n",
        "  model_gpt.summary()\n",
        "\n",
        "  return model_gpt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1nuzFDLhTNSi"
      },
      "source": [
        "### Fit Model w/o Headlines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ef2cd418-2f56-45e2-8aea-25c8444422bc",
        "id": "0Mq40q7pTNSj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        }
      },
      "source": [
        "os.chdir('/gdrive/My Drive/colab_notebooks/information_systems/data/model_checkpoints')\n",
        "callbacks = [ModelCheckpoint(filepath='seq2seq_classifier_article_{epoch:02d}-{val_loss:.2f}.hdf5'), \n",
        "             EarlyStopping(monitor='val_loss', patience=3, verbose=1, min_delta=1e-4, restore_best_weights=True)]\n",
        "\n",
        "model_GRU_Keras = build_GRU_Keras_article()\n",
        "model_GRU_Keras.fit(train_sequences_article, EPU_train_full['Label'].values, epochs=15, \n",
        "                    verbose=1, batch_size=56, validation_split=0.3, shuffle=True, callbacks=callbacks)\n",
        "\n",
        "model_GRU_Keras.save('seq2seq_classifier_article_01.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Entity <bound method Attention.call of <attention_02.Attention object at 0x7f8597a327b8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Attention.call of <attention_02.Attention object at 0x7f8597a327b8>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 550, 768)          41286912  \n",
            "_________________________________________________________________\n",
            "bidirectional_6 (Bidirection (None, 550, 360)          1026000   \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 550, 360)          0         \n",
            "_________________________________________________________________\n",
            "attention_5 (Attention)      (None, 360)               910       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 361       \n",
            "=================================================================\n",
            "Total params: 42,314,183\n",
            "Trainable params: 1,027,271\n",
            "Non-trainable params: 41,286,912\n",
            "_________________________________________________________________\n",
            "Train on 177652 samples, validate on 76137 samples\n",
            "Epoch 1/15\n",
            "177652/177652 [==============================] - 405s 2ms/sample - loss: 0.0429 - acc: 0.9901 - val_loss: 0.0335 - val_acc: 0.9918\n",
            "Epoch 2/15\n",
            "177652/177652 [==============================] - 397s 2ms/sample - loss: 0.0326 - acc: 0.9925 - val_loss: 0.0335 - val_acc: 0.9931\n",
            "Epoch 3/15\n",
            "177652/177652 [==============================] - 399s 2ms/sample - loss: 0.0288 - acc: 0.9936 - val_loss: 0.0299 - val_acc: 0.9931\n",
            "Epoch 4/15\n",
            "177652/177652 [==============================] - 405s 2ms/sample - loss: 0.0264 - acc: 0.9943 - val_loss: 0.0341 - val_acc: 0.9922\n",
            "Epoch 5/15\n",
            "177652/177652 [==============================] - 397s 2ms/sample - loss: 0.0236 - acc: 0.9947 - val_loss: 0.0295 - val_acc: 0.9930\n",
            "Epoch 6/15\n",
            "177652/177652 [==============================] - 398s 2ms/sample - loss: 0.0205 - acc: 0.9954 - val_loss: 0.0369 - val_acc: 0.9915\n",
            "Epoch 7/15\n",
            "177652/177652 [==============================] - 399s 2ms/sample - loss: 0.0176 - acc: 0.9958 - val_loss: 0.0335 - val_acc: 0.9927\n",
            "Epoch 8/15\n",
            "177632/177652 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9964Restoring model weights from the end of the best epoch.\n",
            "177652/177652 [==============================] - 398s 2ms/sample - loss: 0.0141 - acc: 0.9964 - val_loss: 0.0421 - val_acc: 0.9931\n",
            "Epoch 00008: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BmjuEkkpTNSl"
      },
      "source": [
        "#### Calculate ROC Curve and AUC Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "2f5bace4-0aca-4d36-c67e-3097a8b63090",
        "id": "2psVm79ZTNSl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "fpr, tpr, thresholds = metrics.roc_curve(EPU_test_full['Label'].values, model_GRU_Keras.predict(test_sequences_article))\n",
        "metrics.auc(fpr, tpr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9434164710808457"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6Wl80gD5rOK",
        "colab_type": "text"
      },
      "source": [
        "## Cross Validation for Winning Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyYb3cUk9hp0",
        "colab_type": "text"
      },
      "source": [
        "### Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXNAJ2Zz5w4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cp1uRcLB9krV",
        "colab_type": "text"
      },
      "source": [
        "### Define Network Builder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUX4bemX8LdL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_network():\n",
        "  \"\"\"Build network for CV.\"\"\"\n",
        "\n",
        "  model_gpt = Sequential() \n",
        "  model_gpt.add(embedding_layer_cv)\n",
        "  model_gpt.add(Bidirectional(CuDNNGRU(180, return_sequences=True)))\n",
        "\n",
        "  model_gpt.add(Dropout(0.3))\n",
        "  model_gpt.add(Attention(max_length_combined))\n",
        "\n",
        "  model_gpt.add(Dense(1, activation=\"sigmoid\"))\n",
        "  model_gpt.compile(loss=\"binary_crossentropy\", optimizer='rmsprop', metrics=[\"accuracy\"])\n",
        "  model_gpt.summary()\n",
        "  \n",
        "  return model_gpt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a18QcKFd9pzU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_loss', patience=2, verbose=1, min_delta=1e-4, restore_best_weights=True)]\n",
        "\n",
        "classifier = KerasClassifier(\n",
        "    build_fn=create_network, \n",
        "    batch_size=56, epochs=8, \n",
        "    validation_split=0.3, verbose=1, \n",
        "    shuffle=True,\n",
        "    callbacks=callbacks\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osxg-6Dt9f0G",
        "colab_type": "text"
      },
      "source": [
        "### Define Data Vessels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DBbsXl09fj1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auc_list = []\n",
        "f1_list = []\n",
        "stored_predictions = pd.DataFrame(columns=['Index', 'Prediction'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANzK6iNL_COx",
        "colab_type": "text"
      },
      "source": [
        "### Fire Cross Validation Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--ALRrki5rA6",
        "colab_type": "code",
        "outputId": "ea995a29-85be-407f-8d9a-ec61b37684a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=54)\n",
        "for train_index, test_index in cv.split(cv_sequences, EPU_cv_frame['Label'].values):\n",
        "\n",
        "    # Slice original data via cv indices.\n",
        "    X_train, X_test = np.asarray(cv_sequences)[train_index], np.asarray(cv_sequences)[test_index]\n",
        "    y_train, y_test = EPU_cv_frame['Label'].values[train_index], EPU_cv_frame['Label'].values[test_index]\n",
        "\n",
        "    # Fit classifier.\n",
        "    classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Predict target using trained (fitted) model.\n",
        "    prediction_out = classifier.predict_proba(X_test)\n",
        "    target_prediction = prediction_out[:, 1]\n",
        "    \n",
        "    # Calculate & store AUC scores.\n",
        "    fpr, tpr, thresholds = metrics.roc_curve(y_test, target_prediction)\n",
        "    roc_auc = metrics.auc(fpr, tpr)\n",
        "    auc_list.append(roc_auc)\n",
        "    \n",
        "    # Store predictions and real target values in results frame.\n",
        "    results_frame = pd.DataFrame({\n",
        "        'Index': test_index, \n",
        "        'Prediction': target_prediction, \n",
        "        'True': y_test\n",
        "        })\n",
        "    \n",
        "    results_frame = results_frame.reset_index(drop=True)\n",
        "\n",
        "    # Add iteration results to master output data frame. \n",
        "    stored_predictions = pd.concat([stored_predictions, results_frame], axis=0)\n",
        "    \n",
        "    # Calculate & store F1 scores.\n",
        "    target_prediction_round = np.around(target_prediction, decimals=0)\n",
        "    f1_list.append(classification_report(y_test, target_prediction_round, output_dict=True)['1']['f1-score'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 570, 768)          42456576  \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 570, 360)          1026000   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 570, 360)          0         \n",
            "_________________________________________________________________\n",
            "attention (Attention)        (None, 360)               930       \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 361       \n",
            "=================================================================\n",
            "Total params: 43,483,867\n",
            "Trainable params: 1,027,291\n",
            "Non-trainable params: 42,456,576\n",
            "_________________________________________________________________\n",
            "Train on 155796 samples, validate on 66771 samples\n",
            "Epoch 1/8\n",
            "155796/155796 [==============================] - 332s 2ms/sample - loss: 0.0148 - acc: 0.9957 - val_loss: 0.2236 - val_acc: 0.9389\n",
            "Epoch 2/8\n",
            "155796/155796 [==============================] - 323s 2ms/sample - loss: 0.0079 - acc: 0.9973 - val_loss: 0.2647 - val_acc: 0.9130\n",
            "Epoch 3/8\n",
            "155792/155796 [============================>.] - ETA: 0s - loss: 0.0065 - acc: 0.9980Restoring model weights from the end of the best epoch.\n",
            "155796/155796 [==============================] - 323s 2ms/sample - loss: 0.0065 - acc: 0.9980 - val_loss: 0.2540 - val_acc: 0.9346\n",
            "Epoch 00003: early stopping\n",
            "55642/55642 [==============================] - 40s 713us/sample\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
            "of pandas will change to not sort by default.\n",
            "\n",
            "To accept the future behavior, pass 'sort=False'.\n",
            "\n",
            "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 570, 768)          42456576  \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 570, 360)          1026000   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 570, 360)          0         \n",
            "_________________________________________________________________\n",
            "attention_1 (Attention)      (None, 360)               930       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 361       \n",
            "=================================================================\n",
            "Total params: 43,483,867\n",
            "Trainable params: 1,027,291\n",
            "Non-trainable params: 42,456,576\n",
            "_________________________________________________________________\n",
            "Train on 155796 samples, validate on 66771 samples\n",
            "Epoch 1/8\n",
            "155796/155796 [==============================] - 327s 2ms/sample - loss: 0.0144 - acc: 0.9954 - val_loss: 0.2726 - val_acc: 0.9008\n",
            "Epoch 2/8\n",
            "155796/155796 [==============================] - 321s 2ms/sample - loss: 0.0073 - acc: 0.9978 - val_loss: 0.5250 - val_acc: 0.8617\n",
            "Epoch 3/8\n",
            "155796/155796 [==============================] - 323s 2ms/sample - loss: 0.0060 - acc: 0.9983 - val_loss: 0.2489 - val_acc: 0.9348\n",
            "Epoch 4/8\n",
            "155796/155796 [==============================] - 323s 2ms/sample - loss: 0.0047 - acc: 0.9988 - val_loss: 0.3166 - val_acc: 0.9370\n",
            "Epoch 5/8\n",
            "155792/155796 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9992Restoring model weights from the end of the best epoch.\n",
            "155796/155796 [==============================] - 323s 2ms/sample - loss: 0.0036 - acc: 0.9992 - val_loss: 0.4127 - val_acc: 0.9061\n",
            "Epoch 00005: early stopping\n",
            "55642/55642 [==============================] - 38s 676us/sample\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 570, 768)          42456576  \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 570, 360)          1026000   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 570, 360)          0         \n",
            "_________________________________________________________________\n",
            "attention_2 (Attention)      (None, 360)               930       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 361       \n",
            "=================================================================\n",
            "Total params: 43,483,867\n",
            "Trainable params: 1,027,291\n",
            "Non-trainable params: 42,456,576\n",
            "_________________________________________________________________\n",
            "Train on 155796 samples, validate on 66771 samples\n",
            "Epoch 1/8\n",
            " 25592/155796 [===>..........................] - ETA: 3:53 - loss: 0.0484 - acc: 0.9865"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goOKGGCY-jfp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/gdrive/My Drive/colab_notebooks/information_systems/data/model_checkpoints')\n",
        "stored_predictions.to_csv('cross_validation_results_03.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tr1KMtlj-s-T",
        "colab_type": "code",
        "outputId": "a4eda16e-9b07-4067-9cab-9c7477a3c5c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "DNN_scores = pd.DataFrame({'AUC': auc_list,'F-score': f1_list})\n",
        "DNN_scores"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AUC</th>\n",
              "      <th>F-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.942321</td>\n",
              "      <td>0.566832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.947261</td>\n",
              "      <td>0.613975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.943178</td>\n",
              "      <td>0.571776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.936210</td>\n",
              "      <td>0.583514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.936837</td>\n",
              "      <td>0.575829</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        AUC   F-score\n",
              "0  0.942321  0.566832\n",
              "1  0.947261  0.613975\n",
              "2  0.943178  0.571776\n",
              "3  0.936210  0.583514\n",
              "4  0.936837  0.575829"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CX6qvSx0GRiD",
        "colab_type": "text"
      },
      "source": [
        "### Match Predictions to Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qPiWtT5dYhmd"
      },
      "source": [
        "#### Merge Tables on Article Text to Transfer Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTIxmjF2YiZp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/gdrive/My Drive/colab_notebooks/information_systems/data/model_checkpoints')\n",
        "stored_predictions = pd.read_csv('cross_validation_results_03.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qVyp4exlA8t2",
        "colab": {}
      },
      "source": [
        "# EPU_final_reindexed = EPU_cv_frame.merge(stored_predictions, on='Headline')[['Index', 'Newspaper', 'Date']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGlOZ_38GSGQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_output = pd.merge(EPU_cv_frame, stored_predictions, left_index=True, right_on='Index')[['Index', 'Newspaper', 'Date', 'Prediction', 'True']]\n",
        "final_output.to_csv('final_output_02.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CupBof9JBGYl",
        "colab_type": "code",
        "outputId": "100f49f2-f282-4b3c-d12a-8e99c2d15692",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "final_output"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Index</th>\n",
              "      <th>Newspaper</th>\n",
              "      <th>Date</th>\n",
              "      <th>Prediction</th>\n",
              "      <th>True</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>222568</th>\n",
              "      <td>0</td>\n",
              "      <td>The Washington Post</td>\n",
              "      <td>2006-01-01</td>\n",
              "      <td>0.997151</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166926</th>\n",
              "      <td>1</td>\n",
              "      <td>The Washington Post</td>\n",
              "      <td>2006-01-01</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166927</th>\n",
              "      <td>2</td>\n",
              "      <td>The Washington Post</td>\n",
              "      <td>2006-01-01</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111284</th>\n",
              "      <td>3</td>\n",
              "      <td>The Washington Post</td>\n",
              "      <td>2006-01-01</td>\n",
              "      <td>0.000031</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111285</th>\n",
              "      <td>4</td>\n",
              "      <td>The Washington Post</td>\n",
              "      <td>2006-01-01</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>278207</th>\n",
              "      <td>278204</td>\n",
              "      <td>The New York Post</td>\n",
              "      <td>2019-04-30</td>\n",
              "      <td>0.180472</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222567</th>\n",
              "      <td>278205</td>\n",
              "      <td>The New York Post</td>\n",
              "      <td>2019-04-30</td>\n",
              "      <td>0.676777</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55640</th>\n",
              "      <td>278206</td>\n",
              "      <td>Pittsburgh Post-Gazette (Pennsylvania)</td>\n",
              "      <td>2019-04-30</td>\n",
              "      <td>0.138745</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>278208</th>\n",
              "      <td>278207</td>\n",
              "      <td>Tampa Bay Times</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55641</th>\n",
              "      <td>278208</td>\n",
              "      <td>Tampa Bay Times</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>278209 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         Index                               Newspaper        Date  \\\n",
              "222568       0                     The Washington Post  2006-01-01   \n",
              "166926       1                     The Washington Post  2006-01-01   \n",
              "166927       2                     The Washington Post  2006-01-01   \n",
              "111284       3                     The Washington Post  2006-01-01   \n",
              "111285       4                     The Washington Post  2006-01-01   \n",
              "...        ...                                     ...         ...   \n",
              "278207  278204                       The New York Post  2019-04-30   \n",
              "222567  278205                       The New York Post  2019-04-30   \n",
              "55640   278206  Pittsburgh Post-Gazette (Pennsylvania)  2019-04-30   \n",
              "278208  278207                         Tampa Bay Times         NaN   \n",
              "55641   278208                         Tampa Bay Times         NaN   \n",
              "\n",
              "        Prediction  True  Label  \n",
              "222568    0.997151   1.0      1  \n",
              "166926    0.000004   0.0      0  \n",
              "166927    0.000021   0.0      0  \n",
              "111284    0.000031   0.0      0  \n",
              "111285    0.000012   0.0      0  \n",
              "...            ...   ...    ...  \n",
              "278207    0.180472   0.0      0  \n",
              "222567    0.676777   0.0      0  \n",
              "55640     0.138745   0.0      0  \n",
              "278208    0.000024   0.0      0  \n",
              "55641     0.000006   0.0      0  \n",
              "\n",
              "[278209 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    }
  ]
}